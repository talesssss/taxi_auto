{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOrKGVZIZ1QyZrTY8cmCvPa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talesssss/taxi_auto/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XolSbzD0sF-L"
      },
      "source": [
        "import numpy as np\n",
        "#import keras.backend.tensorflow_backend as backend\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import PIL\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvpLsyV6NW71",
        "outputId": "e987cbd3-e71b-462c-ff03-0a7863f4c7e0"
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1o_Jdd9M01hGatdcM9x2Lb3mSUCILfEWc'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded content \"{\"nbformat\":4,\"nbformat_minor\":0,\"metadata\":{\"colab\":{\"name\":\"Untitled1.ipynb\",\"provenance\":[],\"machine_shape\":\"hm\",\"authorship_tag\":\"ABX9TyOz/X18keQlIViom6q6/5w1\"},\"kernelspec\":{\"name\":\"python3\",\"display_name\":\"Python 3\"},\"language_info\":{\"name\":\"python\"},\"accelerator\":\"GPU\"},\"cells\":[{\"cell_type\":\"code\",\"metadata\":{\"id\":\"XolSbzD0sF-L\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1623677182467,\"user_tz\":180,\"elapsed\":337,\"user\":{\"displayName\":\"TalesGameplays\",\"photoUrl\":\"https://lh3.googleusercontent.com/a-/AOh14GjkBygC6Lkr5hnKNSGdmjzZBu341_03zqwpyPGl=s64\",\"userId\":\"02807279484566734138\"}}},\"source\":[\"import numpy as np\\n\",\"#import keras.backend.tensorflow_backend as backend\\n\",\"from keras.models import Sequential\\n\",\"from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten\\n\",\"from keras.optimizers import Adam\\n\",\"from keras.callbacks import TensorBoard\\n\",\"import tensorflow as tf\\n\",\"from collections import deque\\n\",\"import time\\n\",\"import random\\n\",\"from tqdm import tqdm\\n\",\"import os\\n\",\"from PIL import Image\\n\",\"import cv2\\n\",\"import PIL\\n\"],\"execution_count\":2,\"outputs\":[]},{\"cell_type\":\"code\",\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":135},\"id\":\"SvpLsyV6NW71\",\"executionInfo\":{\"status\":\"error\",\"timestamp\":1623702652063,\"user_tz\":180,\"elapsed\":305,\"user\":{\"displayName\":\"TalesGameplays\",\"photoUrl\":\"https://lh3.googleusercontent.com/a-/AOh14GjkBygC6Lkr5hnKNSGdmjzZBu341_03zqwpyPGl=s64\",\"userId\":\"02807279484566734138\"}},\"outputId\":\"e29a3f78-f50a-44df-9182-7ed49099a5b6\"},\"source\":[\"# Import PyDrive and associated libraries.\\n\",\"# This only needs to be done once per notebook.\\n\",\"from pydrive.auth import GoogleAuth\\n\",\"from pydrive.drive import GoogleDrive\\n\",\"from google.colab import auth\\n\",\"from oauth2client.client import GoogleCredentials\\n\",\"\\n\",\"# Authenticate and create the PyDrive client.\\n\",\"# This only needs to be done once per notebook.\\n\",\"auth.authenticate_user()\\n\",\"gauth = GoogleAuth()\\n\",\"gauth.credentials = GoogleCredentials.get_application_default()\\n\",\"drive = GoogleDrive(gauth)\\n\",\"\\n\",\"# Download a file based on its file ID.\\n\",\"#\\n\",\"# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\\n\",\"file_id = '1o_Jdd9M01hGatdcM9x2Lb3mSUCILfEWc#scrollTo=SvpLsyV6NW71'\\n\",\"downloaded = drive.CreateFile({'id': file_id})\\n\",\"print('Downloaded content \\\"{}\\\"'.format(downloaded.GetContentString()))\"],\"execution_count\":9,\"outputs\":[{\"output_type\":\"error\",\"ename\":\"SyntaxError\",\"evalue\":\"ignored\",\"traceback\":[\"\\u001b[0;36m  File \\u001b[0;32m\\\"<ipython-input-9-a35a88e655d7>\\\"\\u001b[0;36m, line \\u001b[0;32m18\\u001b[0m\\n\\u001b[0;31m    file_id = 1o_Jdd9M01hGatdcM9x2Lb3mSUCILfEWc#scrollTo=SvpLsyV6NW71\\u001b[0m\\n\\u001b[0m                                              ^\\u001b[0m\\n\\u001b[0;31mSyntaxError\\u001b[0m\\u001b[0;31m:\\u001b[0m invalid syntax\\n\"]}]},{\"cell_type\":\"code\",\"metadata\":{\"colab\":{\"base_uri\":\"https://localhost:8080/\"},\"id\":\"IztkN6ezrqtK\",\"executionInfo\":{\"status\":\"ok\",\"timestamp\":1623702383039,\"user_tz\":180,\"elapsed\":25095891,\"user\":{\"displayName\":\"TalesGameplays\",\"photoUrl\":\"https://lh3.googleusercontent.com/a-/AOh14GjkBygC6Lkr5hnKNSGdmjzZBu341_03zqwpyPGl=s64\",\"userId\":\"02807279484566734138\"}},\"outputId\":\"b5c7f540-9115-4d57-d14f-acc0b694f8de\"},\"source\":[\"\\n\",\"\\n\",\"DISCOUNT = 0.99\\n\",\"REPLAY_MEMORY_SIZE = 50_000  # How many last steps to keep for model training\\n\",\"MIN_REPLAY_MEMORY_SIZE = 1_000  # Minimum number of steps in a memory to start training\\n\",\"MINIBATCH_SIZE = 64  # How many steps (samples) to use for training\\n\",\"UPDATE_TARGET_EVERY = 5  # Terminal states (end of episodes)\\n\",\"MODEL_NAME = '2x256'\\n\",\"MIN_REWARD = -200  # For model save\\n\",\"MEMORY_FRACTION = 0.20\\n\",\"\\n\",\"# Environment settings\\n\",\"EPISODES =15000\\n\",\"\\n\",\"# Exploration settings\\n\",\"epsilon = 1  # not a constant, going to be decayed\\n\",\"EPSILON_DECAY =0.99985\\n\",\"MIN_EPSILON = 0.001\\n\",\"\\n\",\"#  Stats settings\\n\",\"AGGREGATE_STATS_EVERY = 50 # episodes\\n\",\"SHOW_PREVIEW = False\\n\",\"\\n\",\"lista = []\\n\",\"\\n\",\"class Blob:\\n\",\"    \\n\",\"\\n\",\"    def __init__(self, size):\\n\",\"        self.size = size\\n\",\"      \\n\",\"        posicao = []\\n\",\"        for x in range (10):\\n\",\"            for y in range (10):\\n\",\"                posicao.append((x,y))\\n\",\"        calcada = [(0,1),(1,2),(2,2),(2,3),(2,5),(3,6),(4,2),(5,2),(6,3),(7,0),(7,1),(8,2),(4,1),(1,6),(2,6),\\n\",\"                           (4,6),(5,6),(6,6),(7,6),(1,8),(2,8),(3,8),(4,8),(5,8),(8,8),(7,8),(0,9),(0,8),(8,9),(4,3),(4,4),(6,4)]\\n\",\"        pedagio = [(6,8),(4,0),(8,5)]\\n\",\"       \\n\",\"        for coord in calcada:\\n\",\"            if coord in posicao:\\n\",\"                posicao.remove(coord)\\n\",\"                \\n\",\"        for coord in pedagio:\\n\",\"            if coord in posicao:\\n\",\"                posicao.remove(coord)\\n\",\"                \\n\",\"        origem_taxi = posicao[random.randint(0, len(posicao)-1)]\\n\",\"        self.x = origem_taxi[0]\\n\",\"        self.y = origem_taxi[1]\\n\",\"        \\n\",\"        posicao.remove(origem_taxi)\\n\",\"        origem_passageiro = posicao[random.randint(0, len(posicao)-1)]\\n\",\"        self.xP = origem_passageiro[0]\\n\",\"        self.yP = origem_passageiro[1]\\n\",\"        \\n\",\"        posicao.remove(origem_passageiro)\\n\",\"        origem_destino = posicao[random.randint(0, len(posicao)-1)]\\n\",\"        self.xd = origem_destino[0]\\n\",\"        self.yd = origem_destino[1]\\n\",\"    \\n\",\"    \\n\",\"    def __str__(self):\\n\",\"        return f\\\"Blob ({self.x}, {self.y})\\\"\\n\",\"\\n\",\"    def __sub__(self, other):\\n\",\"        return (self.x-other.x, self.y-other.y)\\n\",\"\\n\",\"    def __eq__(self, other):\\n\",\"        return self.x == other.x and self.y == other.y\\n\",\"      \\n\",\"        #for i in calcada:\\n\",\"            #return self.x == calcada[0] and self.y == calcada[1]\\n\",\"    \\n\",\"    \\n\",\"    \\n\",\"    \\n\",\"    def action(self, choice):\\n\",\"        '''\\n\",\"        Gives us 9 total movement options. (0,1,2,3,4,5,6,7,8)\\n\",\"        '''\\n\",\"        if choice == 0:\\n\",\"            self.move(x=1, y=1)\\n\",\"        elif choice == 1:\\n\",\"            self.move(x=-1, y=-1)\\n\",\"        elif choice == 2:\\n\",\"            self.move(x=-1, y=1)\\n\",\"        elif choice == 3:\\n\",\"            self.move(x=1, y=-1)\\n\",\"        elif choice == 4:\\n\",\"            self.move(x=1, y=0)\\n\",\"        elif choice == 5:\\n\",\"            self.move(x=-1, y=0)\\n\",\"        elif choice == 6:\\n\",\"            self.move(x=0, y=1)\\n\",\"        elif choice == 7:\\n\",\"            self.move(x=0, y=-1)\\n\",\"        elif choice == 8:\\n\",\"            self.move(x=0, y=0)\\n\",\"\\n\",\"    def move(self, x=False, y=False):\\n\",\"\\n\",\"        # If no value for x, move randomly\\n\",\"        if not x:\\n\",\"            self.x += x\\n\",\"        else:\\n\",\"            self.x += x\\n\",\"\\n\",\"        # If no value for y, move randomly\\n\",\"        if not y:\\n\",\"            self.y += y\\n\",\"        else:\\n\",\"            self.y += y\\n\",\"\\n\",\"        # If we are out of bounds, fix!\\n\",\"        if self.x < 0:\\n\",\"            self.x = 0\\n\",\"        elif self.x > self.size-1:\\n\",\"            self.x = self.size-1\\n\",\"        if self.y < 0:\\n\",\"            self.y = 0\\n\",\"        elif self.y > self.size-1:\\n\",\"            self.y = self.size-1\\n\",\"\\n\",\"\\n\",\"class BlobEnv:\\n\",\"    SIZE = 10\\n\",\"    RETURN_IMAGES = True\\n\",\"    MOVE_PENALTY = 1\\n\",\"    ENEMY_PENALTY = 200\\n\",\"    PASSAGEIRO_REWARD = 60\\n\",\"    PEDAGIO_PENALTY = 5\\n\",\"    DESTINO_REWARD = 150\\n\",\"    OBSERVATION_SPACE_VALUES = (SIZE, SIZE, 3)  # 4\\n\",\"    ACTION_SPACE_SIZE = 9\\n\",\"    PLAYER_N = 1  # player key in dict\\n\",\"    PASSAGEIRO_N = 2  # passageiro key in dict\\n\",\"    ENEMY_N = 3  # enemy key in dict\\n\",\"    PEDAGIO_N = 4\\n\",\"    DESTINO_N = 5\\n\",\"    \\n\",\"    # the dict! (colors)\\n\",\"    d = {1: (0, 255, 255),\\n\",\"         2: (255, 255, 255),\\n\",\"         3: (100, 100, 100),\\n\",\"         4: (0,0,150),\\n\",\"         5: (0,200,0)}\\n\",\"\\n\",\"    def reset(self):\\n\",\"        \\n\",\"        self.player = Blob(self.SIZE)\\n\",\"        self.passageiro = Blob(self.SIZE)\\n\",\"        self.destino = Blob(self.SIZE)\\n\",\"        \\n\",\"        while self.passageiro == self.player:\\n\",\"            self.passageiro = Blob(self.SIZE)\\n\",\"            \\n\",\"        while self.destino == self.player:\\n\",\"            self.destino = Blob(self.SIZE)\\n\",\"    \\n\",\"        #self.enemy = Blob(self.SIZE)\\n\",\"       # while self.enemy == self.player and self.enemy == self.passageiro :\\n\",\"         #   self.enemy = Blob(self.SIZE)\\n\",\"    \\n\",\"\\n\",\"        self.episode_step = 0\\n\",\"\\n\",\"        if self.RETURN_IMAGES:\\n\",\"            observation = np.array(self.get_image())\\n\",\"        else:\\n\",\"            observation = (self.player-self.passageiro) + (self.player-self.enemy)\\n\",\"        return observation\\n\",\"    \\n\",\"    def step(self, action):\\n\",\"        \\n\",\"        self.episode_step += 1\\n\",\"        self.player.action(action)\\n\",\"        \\n\",\"        \\n\",\"\\n\",\"        if self.RETURN_IMAGES:\\n\",\"            new_observation = np.array(self.get_image())\\n\",\"        else:\\n\",\"            new_observation = (self.player-self.passageiro) + (self.player-self.enemy)\\n\",\"        \\n\",\"        calcada = [(0,1),(1,2),(2,2),(2,3),(2,5),(3,6),(4,2),(5,2),(6,3),(7,0),(7,1),(8,2),(4,1),(1,6),(2,6),\\n\",\"                           (4,6),(5,6),(6,6),(7,6),(1,8),(3,8),(4,8),(5,8),(8,8),(7,8),(0,9),(0,8),(8,9),(8,5),(4,3),(4,4),(6,4)]\\n\",\"        \\n\",\"        global lista\\n\",\"    \\n\",\"    \\n\",\"        if self.player.x == self.destino.xd and self.player.y == self.destino.yd and len(lista)>0 :\\n\",\"            reward = self.DESTINO_REWARD\\n\",\"            \\n\",\"        elif self.player.x == self.destino.xd and self.player.y == self.destino.yd and len(lista)==0 :\\n\",\"            reward = -self.MOVE_PENALTY\\n\",\"        \\n\",\"        elif (self.player.x == 0 and self.player.y == 1) | (self.player.x == 1 and self.player.y == 2) | (self.player.x == 2 and self.player.y == 2) | (self.player.x == 2 and self.player.y == 3) |(self.player.x == 2 and self.player.y == 5) | (self.player.x == 3 and self.player.y == 6):\\n\",\"            reward = -self.ENEMY_PENALTY\\n\",\"            \\n\",\"        elif (self.player.x == 4 and self.player.y == 2) | (self.player.x == 5 and self.player.y == 2) | (self.player.x == 6 and self.player.y == 3) | (self.player.x == 7 and self.player.y == 0) |(self.player.x == 7 and self.player.y == 1) | (self.player.x == 8 and self.player.y == 2):\\n\",\"            reward = -self.ENEMY_PENALTY\\n\",\"            \\n\",\"        elif (self.player.x == 4 and self.player.y == 1) | (self.player.x == 1 and self.player.y == 6) | (self.player.x == 2 and self.player.y == 6) | (self.player.x == 4 and self.player.y == 6) |(self.player.x == 5 and self.player.y == 6) | (self.player.x == 6 and self.player.y == 6):\\n\",\"            reward = -self.ENEMY_PENALTY\\n\",\"            \\n\",\"        elif (self.player.x == 7 and self.player.y == 6) | (self.player.x == 1 and self.player.y == 8) | (self.player.x == 3 and self.player.y == 8) | (self.player.x == 4 and self.player.y == 8) |(self.player.x == 5 and self.player.y == 8) | (self.player.x == 8 and self.player.y == 8):\\n\",\"            reward = -self.ENEMY_PENALTY\\n\",\"            \\n\",\"        elif (self.player.x == 7 and self.player.y == 8) | (self.player.x == 0 and self.player.y == 9) | (self.player.x == 0 and self.player.y == 8) | (self.player.x == 8 and self.player.y == 9) | (self.player.x == 4 and self.player.y == 3):\\n\",\"            reward = -self.ENEMY_PENALTY\\n\",\"            \\n\",\"        elif (self.player.x == 4 and self.player.y == 4) | (self.player.x == 6 and self.player.y == 4):\\n\",\"            reward = -self.ENEMY_PENALTY\\n\",\"        \\n\",\"        elif self.player.x == self.passageiro.xP and self.player.y == self.passageiro.yP and len(lista)==0:\\n\",\"            reward = self.PASSAGEIRO_REWARD\\n\",\"            lista.append(1)\\n\",\"            \\n\",\"        elif (self.player.x == 6 and self.player.y == 8) | (self.player.x == 4 and self.player.y == 0) | (self.player.x == 8 and self.player.y == 5):\\n\",\"            reward = -self.PEDAGIO_PENALTY\\n\",\"        \\n\",\"        else:\\n\",\"            reward = -self.MOVE_PENALTY\\n\",\"\\n\",\"        done = False\\n\",\"        \\n\",\"        if reward == self.DESTINO_REWARD or reward == -self.ENEMY_PENALTY or self.episode_step >= 200:\\n\",\"            lista.clear()\\n\",\"            done = True\\n\",\"        \\n\",\"        #print(lista)\\n\",\"        \\n\",\"        return new_observation, reward, done\\n\",\"\\n\",\"\\n\",\"    \\n\",\"    def render(self):\\n\",\"        img = self.get_image()\\n\",\"        img = img.resize((10, 10),PIL.Image.NEAREST)  # resizing so we can see our agent in all its glory.\\n\",\"        cv2.imshow(\\\"image\\\", np.array(img))  # show it!\\n\",\"        cv2.waitKey(1)\\n\",\"\\n\",\"    # FOR CNN #\\n\",\"    def get_image(self):\\n\",\"        \\n\",\"        calcada = [(0,1),(1,2),(2,2),(2,3),(2,5),(3,6),(4,2),(5,2),(6,3),(7,0),(7,1),(8,2),(4,1),(1,6),(2,6),\\n\",\"                           (4,6),(5,6),(6,6),(7,6),(1,8),(3,8),(4,8),(5,8),(8,8),(7,8),(0,9),(0,8),(8,9),(4,3),(4,4),(6,4)]\\n\",\"        pedagio = [(6,8),(4,0),(8,5)]\\n\",\"    \\n\",\"        env = np.zeros((self.SIZE, self.SIZE, 3), dtype=np.uint8)  # starts an rbg of our size\\n\",\"        #env[self.passageiro.x][self.passageiro.y] = self.d[self.passageiro_N]  # sets the passageiro location tile to green color\\n\",\"        env[self.passageiro.xP][self.passageiro.yP] = self.d[self.PASSAGEIRO_N]  # sets the passageiro location tile to green color\\n\",\"        for i in calcada:\\n\",\"            env[i[0]][i[1]] = self.d[self.ENEMY_N]\\n\",\"        env[self.player.x][self.player.y] = self.d[self.PLAYER_N]  # sets the player tile to blue\\n\",\"       \\n\",\"        for i in pedagio:\\n\",\"            env[i[0]][i[1]] = self.d[self.PEDAGIO_N]\\n\",\"            \\n\",\"        env[self.destino.xd][self.destino.yd] = self.d[self.DESTINO_N]  # sets the passageiro location tile to green color\\n\",\"     \\n\",\"        img = Image.fromarray(env, 'RGB')  # reading to rgb. Apparently. Even tho color definitions are bgr. ???\\n\",\"        return img\\n\",\"\\n\",\"\\n\",\"env = BlobEnv()\\n\",\"\\n\",\"# For stats\\n\",\"ep_rewards = [-200]\\n\",\"\\n\",\"# For more repetitive results\\n\",\"random.seed(1)\\n\",\"np.random.seed(1)\\n\",\"tf.random.set_seed(1)\\n\",\"#tf.set_random_seed(1)\\n\",\"\\n\",\"# Memory fraction, used mostly when trai8ning multiple agents\\n\",\"#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=MEMORY_FRACTION)\\n\",\"#backend.set_session(tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)))\\n\",\"\\n\",\"gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=MEMORY_FRACTION)\\n\",\"tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\\n\",\"  \\n\",\"\\n\",\"\\n\",\"# Create models folder\\n\",\"if not os.path.isdir('models'):\\n\",\"    os.makedirs('models')\\n\",\"\\n\",\"\\n\",\"# Own Tensorboard class\\n\",\"class ModifiedTensorBoard(TensorBoard):\\n\",\"    def __init__(self, **kwargs):\\n\",\"        super().__init__(**kwargs)\\n\",\"        self.step = 1\\n\",\"        self.writer = tf.summary.create_file_writer(self.log_dir)\\n\",\"        self._log_write_dir = self.log_dir\\n\",\"\\n\",\"    def set_model(self, model):\\n\",\"        self.model = model\\n\",\"\\n\",\"        self._train_dir = os.path.join(self._log_write_dir, 'train')\\n\",\"        self._train_step = self.model._train_counter\\n\",\"\\n\",\"        self._val_dir = os.path.join(self._log_write_dir, 'validation')\\n\",\"        self._val_step = self.model._test_counter\\n\",\"\\n\",\"        self._should_write_train_graph = False\\n\",\"\\n\",\"    def on_epoch_end(self, epoch, logs=None):\\n\",\"        self.update_stats(**logs)\\n\",\"\\n\",\"    def on_batch_end(self, batch, logs=None):\\n\",\"        pass\\n\",\"\\n\",\"    def on_train_end(self, _):\\n\",\"        pass\\n\",\"\\n\",\"    def update_stats(self, **stats):\\n\",\"        with self.writer.as_default():\\n\",\"            for key, value in stats.items():\\n\",\"                tf.summary.scalar(key, value, step = self.step)\\n\",\"                self.writer.flush()                \\n\",\"\\n\",\"   \\n\",\"        \\n\",\"# Agent class\\n\",\"class DQNAgent:\\n\",\"    def __init__(self):\\n\",\"\\n\",\"        # Main model\\n\",\"        self.model = self.create_model()\\n\",\"\\n\",\"        # Target network\\n\",\"        self.target_model = self.create_model()\\n\",\"        self.target_model.set_weights(self.model.get_weights())\\n\",\"\\n\",\"        # An array with last n steps for training\\n\",\"        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\\n\",\"\\n\",\"        # Custom tensorboard object\\n\",\"        self.tensorboard = ModifiedTensorBoard(log_dir=\\\"logs/fit/{}-{}\\\".format(MODEL_NAME, int(time.time())))\\n\",\"\\n\",\"        # Used to count when to update target network with main network's weights\\n\",\"        self.target_update_counter = 0\\n\",\"\\n\",\"    def create_model(self):\\n\",\"        model = Sequential()\\n\",\"\\n\",\"        model.add(Conv2D(256, (3, 3), input_shape=env.OBSERVATION_SPACE_VALUES))  # OBSERVATION_SPACE_VALUES = (10, 10, 3) a 10x10 RGB image.\\n\",\"        model.add(Activation('relu'))\\n\",\"        model.add(MaxPooling2D(pool_size=(2, 2)))\\n\",\"        model.add(Dropout(0.2))\\n\",\"\\n\",\"        model.add(Conv2D(256, (3, 3)))\\n\",\"        model.add(Activation('relu'))\\n\",\"        model.add(MaxPooling2D(pool_size=(2, 2)))\\n\",\"        model.add(Dropout(0.2))\\n\",\"\\n\",\"        model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\\n\",\"        model.add(Dense(64))\\n\",\"\\n\",\"        model.add(Dense(env.ACTION_SPACE_SIZE, activation='linear'))  # ACTION_SPACE_SIZE = how many choices (9)\\n\",\"        model.compile(loss=\\\"mse\\\", optimizer=Adam(lr=0.001), metrics=['accuracy'])\\n\",\"        return model\\n\",\"\\n\",\"    # Adds step's data to a memory replay array\\n\",\"    # (observation space, action, reward, new observation space, done)\\n\",\"    def update_replay_memory(self, transition):\\n\",\"        self.replay_memory.append(transition)\\n\",\"\\n\",\"    # Trains main network every step during episode\\n\",\"    def train(self, terminal_state, step):\\n\",\"\\n\",\"        # Start training only if certain number of samples is already saved\\n\",\"        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\\n\",\"            return\\n\",\"\\n\",\"        # Get a minibatch of random samples from memory replay table\\n\",\"        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\\n\",\"\\n\",\"        # Get current states from minibatch, then query NN model for Q values\\n\",\"        current_states = np.array([transition[0] for transition in minibatch])/255\\n\",\"        current_qs_list = self.model.predict(current_states)\\n\",\"\\n\",\"        # Get future states from minibatch, then query NN model for Q values\\n\",\"        # When using target network, query it, otherwise main network should be queried\\n\",\"        new_current_states = np.array([transition[3] for transition in minibatch])/255\\n\",\"        future_qs_list = self.target_model.predict(new_current_states)\\n\",\"\\n\",\"        X = []\\n\",\"        y = []\\n\",\"\\n\",\"        # Now we need to enumerate our batches\\n\",\"        for index, (current_state, action, reward, new_current_state, done) in enumerate(minibatch):\\n\",\"\\n\",\"            # If not a terminal state, get new q from future states, otherwise set it to 0\\n\",\"            # almost like with Q Learning, but we use just part of equation here\\n\",\"            if not done:\\n\",\"                max_future_q = np.max(future_qs_list[index])\\n\",\"                new_q = reward + DISCOUNT * max_future_q\\n\",\"            else:\\n\",\"                new_q = reward\\n\",\"\\n\",\"            # Update Q value for given state\\n\",\"            current_qs = current_qs_list[index]\\n\",\"            current_qs[action] = new_q\\n\",\"\\n\",\"            # And append to our training data\\n\",\"            X.append(current_state)\\n\",\"            y.append(current_qs)\\n\",\"\\n\",\"        # Fit on all samples as one batch, log only on terminal state\\n\",\"        self.model.fit(np.array(X)/255, np.array(y), batch_size=MINIBATCH_SIZE, verbose=0, shuffle=False, callbacks=[self.tensorboard] if terminal_state else None)\\n\",\"\\n\",\"        # Update target network counter every episode\\n\",\"        if terminal_state:\\n\",\"            self.target_update_counter += 1\\n\",\"\\n\",\"        # If counter reaches set value, update target network with weights of main network\\n\",\"        if self.target_update_counter > UPDATE_TARGET_EVERY:\\n\",\"            self.target_model.set_weights(self.model.get_weights())\\n\",\"            self.target_update_counter = 0\\n\",\"\\n\",\"    # Queries main network for Q values given current observation space (environment state)\\n\",\"    def get_qs(self, state):\\n\",\"        return self.model.predict(np.array(state).reshape(-1, *state.shape)/255)[0]\\n\",\"\\n\",\"\\n\",\"agent = DQNAgent()\\n\",\"\\n\",\"# Iterate over episodes\\n\",\"for episode in tqdm(range(1, EPISODES + 1), ascii=True, unit='episodes'):\\n\",\"\\n\",\"    # Update tensorboard step every episode\\n\",\"    agent.tensorboard.step = episode\\n\",\"\\n\",\"    # Restarting episode - reset episode reward and step number\\n\",\"    episode_reward = 0\\n\",\"    step = 1\\n\",\"\\n\",\"    # Reset environment and get initial state\\n\",\"    current_state = env.reset()\\n\",\"\\n\",\"    # Reset flag and start iterating until episode ends\\n\",\"    done = False\\n\",\"    while not done:\\n\",\"\\n\",\"        # This part stays mostly the same, the change is to query a model for Q values\\n\",\"        if np.random.random() > epsilon:\\n\",\"            # Get action from Q table\\n\",\"            action = np.argmax(agent.get_qs(current_state))\\n\",\"        else:\\n\",\"            # Get random action\\n\",\"            action = np.random.randint(0, env.ACTION_SPACE_SIZE)\\n\",\"\\n\",\"        new_state, reward, done = env.step(action)\\n\",\"\\n\",\"        # Transform new continous state to new discrete state and count reward\\n\",\"        episode_reward += reward\\n\",\"\\n\",\"        if SHOW_PREVIEW and not episode % AGGREGATE_STATS_EVERY:\\n\",\"            env.render()\\n\",\"\\n\",\"        # Every step we update replay memory and train main network\\n\",\"        agent.update_replay_memory((current_state, action, reward, new_state, done))\\n\",\"        agent.train(done, step)\\n\",\"\\n\",\"        current_state = new_state\\n\",\"        step += 1\\n\",\"\\n\",\"    # Append episode reward to a list and log stats (every given number of episodes)\\n\",\"    ep_rewards.append(episode_reward)\\n\",\"    if not episode % AGGREGATE_STATS_EVERY or episode == 1:\\n\",\"        average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:])/len(ep_rewards[-AGGREGATE_STATS_EVERY:])\\n\",\"        min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:])\\n\",\"        max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:])\\n\",\"        agent.tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward, reward_max=max_reward, epsilon=epsilon)\\n\",\"\\n\",\"        # Save model, but only when min reward is greater or equal a set value\\n\",\"        #if min_reward >= MIN_REWARD:\\n\",\"        agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg_{min_reward:_>7.2f}min__{int(time.time())}.model')\\n\",\"\\n\",\"    # Decay epsilon\\n\",\"    if epsilon > MIN_EPSILON:\\n\",\"        epsilon *= EPSILON_DECAY\\n\",\"        epsilon = max(MIN_EPSILON, epsilon)\"],\"execution_count\":3,\"outputs\":[{\"output_type\":\"stream\",\"text\":[\"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\\n\",\"  \\\"The `lr` argument is deprecated, use `learning_rate` instead.\\\")\\n\",\"  0%|          | 0/15000 [00:00<?, ?episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-202.50avg_-205.00min__1623677288.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"\\r  0%|          | 1/15000 [00:06<26:54:21,  6.46s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-199.68avg_-230.00min__1623677294.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  0%|          | 62/15000 [00:22<14:42:46,  3.55s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___204.00max_-193.90avg_-240.00min__1623677310.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  1%|          | 139/15000 [00:23<7:11:54,  1.74s/episodes] \"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-149.00max_-204.70avg_-239.00min__1623677311.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  1%|1         | 198/15000 [00:24<3:34:50,  1.15episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-148.00max_-202.66avg_-252.00min__1623677312.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  2%|1         | 245/15000 [00:40<2:07:00,  1.94episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-201.82avg_-219.00min__1623677330.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  2%|1         | 299/15000 [01:07<1:35:44,  2.56episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-147.00max_-204.00avg_-226.00min__1623677355.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  2%|2         | 349/15000 [01:31<2:04:39,  1.96episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-201.86avg_-219.00min__1623677380.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  3%|2         | 399/15000 [01:47<48:27,  5.02episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-201.28avg_-227.00min__1623677395.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  3%|2         | 448/15000 [02:17<2:38:05,  1.53episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-176.00max_-204.28avg_-230.00min__1623677425.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  3%|3         | 499/15000 [02:45<1:57:46,  2.05episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-203.56avg_-239.00min__1623677454.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  4%|3         | 549/15000 [03:05<1:55:55,  2.08episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-202.72avg_-231.00min__1623677474.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  4%|3         | 599/15000 [03:30<3:19:22,  1.20episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-198.16avg_-246.00min__1623677498.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  4%|4         | 649/15000 [03:53<1:35:02,  2.52episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-200.68avg_-229.00min__1623677522.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  5%|4         | 699/15000 [04:15<2:33:00,  1.56episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-201.98avg_-222.00min__1623677545.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  5%|4         | 749/15000 [04:39<3:09:02,  1.26episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-204.42avg_-226.00min__1623677568.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  5%|5         | 799/15000 [05:04<1:43:20,  2.29episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-204.10avg_-222.00min__1623677592.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  6%|5         | 849/15000 [05:30<1:14:18,  3.17episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-203.46avg_-231.00min__1623677619.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  6%|5         | 899/15000 [05:54<1:06:27,  3.54episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-153.00max_-202.84avg_-223.00min__1623677642.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  6%|6         | 949/15000 [06:24<2:31:49,  1.54episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-145.00max_-202.00avg_-233.00min__1623677672.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  7%|6         | 999/15000 [06:46<1:29:52,  2.60episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-200.40avg_-223.00min__1623677694.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  7%|6         | 1049/15000 [07:08<2:03:06,  1.89episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-203.94avg_-232.00min__1623677717.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  7%|7         | 1098/15000 [07:30<2:03:43,  1.87episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-154.00max_-202.84avg_-225.00min__1623677738.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  8%|7         | 1149/15000 [08:02<1:32:50,  2.49episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-148.00max_-206.68avg_-251.00min__1623677771.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  8%|7         | 1198/15000 [08:32<2:39:17,  1.44episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-204.94avg_-228.00min__1623677800.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  8%|8         | 1249/15000 [08:53<2:05:01,  1.83episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-200.70avg_-228.00min__1623677822.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  9%|8         | 1299/15000 [09:16<1:32:12,  2.48episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-203.58avg_-222.00min__1623677844.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  9%|8         | 1349/15000 [09:40<1:59:20,  1.91episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-159.00max_-202.78avg_-215.00min__1623677868.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"  9%|9         | 1399/15000 [10:06<1:55:13,  1.97episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-145.00max_-203.06avg_-236.00min__1623677895.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 10%|9         | 1448/15000 [10:40<2:27:17,  1.53episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-155.00max_-204.80avg_-236.00min__1623677928.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 10%|9         | 1499/15000 [11:05<1:17:01,  2.92episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-202.44avg_-227.00min__1623677953.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 10%|#         | 1549/15000 [11:27<1:06:41,  3.36episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-149.00max_-202.96avg_-216.00min__1623677976.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 11%|#         | 1599/15000 [11:55<2:20:05,  1.59episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-200.02avg_-230.00min__1623678003.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 11%|#         | 1649/15000 [12:18<1:37:34,  2.28episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-202.76avg_-218.00min__1623678027.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 11%|#1        | 1699/15000 [12:47<1:39:53,  2.22episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-205.10avg_-226.00min__1623678056.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 12%|#1        | 1749/15000 [13:28<4:38:11,  1.26s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-209.26avg_-259.00min__1623678096.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 12%|#1        | 1799/15000 [13:52<1:40:30,  2.19episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___203.00max_-194.64avg_-222.00min__1623678121.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 12%|#2        | 1849/15000 [14:11<1:52:57,  1.94episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-199.18avg_-213.00min__1623678140.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 13%|#2        | 1899/15000 [14:39<1:27:12,  2.50episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-204.66avg_-222.00min__1623678167.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 13%|#2        | 1949/15000 [15:05<1:26:07,  2.53episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-201.96avg_-237.00min__1623678194.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 13%|#3        | 1998/15000 [15:27<1:40:55,  2.15episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-148.00max_-201.16avg_-216.00min__1623678216.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 14%|#3        | 2049/15000 [15:54<2:09:38,  1.67episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-153.00max_-203.78avg_-226.00min__1623678243.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 14%|#3        | 2099/15000 [16:28<1:51:36,  1.93episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-145.00max_-205.38avg_-248.00min__1623678277.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 14%|#4        | 2148/15000 [16:52<1:34:43,  2.26episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-204.04avg_-227.00min__1623678300.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 15%|#4        | 2199/15000 [17:20<1:44:59,  2.03episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___197.00max_-196.26avg_-247.00min__1623678330.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 15%|#4        | 2249/15000 [17:55<1:25:12,  2.49episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-202.32avg_-236.00min__1623678364.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 15%|#5        | 2298/15000 [18:28<6:59:05,  1.98s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-202.88avg_-222.00min__1623678398.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 16%|#5        | 2349/15000 [18:58<1:43:30,  2.04episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-202.36avg_-264.00min__1623678426.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 16%|#5        | 2399/15000 [19:27<3:18:03,  1.06episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-195.86avg_-232.00min__1623678455.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 16%|#6        | 2449/15000 [20:05<3:49:00,  1.09s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-204.54avg_-237.00min__1623678493.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 17%|#6        | 2498/15000 [20:32<1:48:22,  1.92episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-200.98avg_-228.00min__1623678521.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 17%|#6        | 2549/15000 [21:09<3:55:56,  1.14s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___205.00max_-195.22avg_-226.00min__1623678558.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 17%|#7        | 2598/15000 [21:46<3:41:41,  1.07s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-151.00max_-206.06avg_-271.00min__1623678594.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 18%|#7        | 2649/15000 [22:13<1:27:39,  2.35episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-205.14avg_-270.00min__1623678622.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 18%|#7        | 2699/15000 [22:46<1:24:06,  2.44episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-206.00avg_-234.00min__1623678657.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 18%|#8        | 2749/15000 [23:21<2:03:37,  1.65episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-200.08avg_-233.00min__1623678690.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 19%|#8        | 2799/15000 [23:50<1:50:32,  1.84episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-200.86avg_-224.00min__1623678718.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 19%|#8        | 2848/15000 [24:22<3:24:09,  1.01s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-205.74avg_-232.00min__1623678751.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 19%|#9        | 2899/15000 [24:56<1:48:04,  1.87episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-202.46avg_-244.00min__1623678787.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 20%|#9        | 2949/15000 [25:28<1:32:23,  2.17episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-205.56avg_-236.00min__1623678816.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 20%|#9        | 2999/15000 [25:57<2:17:58,  1.45episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-205.14avg_-221.00min__1623678846.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 20%|##        | 3049/15000 [26:33<2:01:53,  1.63episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-152.00max_-205.76avg_-266.00min__1623678881.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 21%|##        | 3099/15000 [27:15<2:20:05,  1.42episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-204.30avg_-265.00min__1623678924.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 21%|##        | 3149/15000 [27:56<2:31:10,  1.31episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-151.00max_-207.40avg_-246.00min__1623678966.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 21%|##1       | 3198/15000 [28:33<3:52:35,  1.18s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-204.26avg_-245.00min__1623679002.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 22%|##1       | 3249/15000 [29:10<1:38:32,  1.99episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-205.66avg_-248.00min__1623679039.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 22%|##1       | 3299/15000 [29:41<1:41:45,  1.92episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-203.38avg_-280.00min__1623679073.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 22%|##2       | 3349/15000 [30:16<1:51:36,  1.74episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-206.62avg_-277.00min__1623679105.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 23%|##2       | 3399/15000 [30:49<2:12:26,  1.46episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-206.10avg_-242.00min__1623679137.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 23%|##2       | 3449/15000 [31:18<1:54:24,  1.68episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-156.00max_-204.38avg_-233.00min__1623679166.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 23%|##3       | 3499/15000 [31:57<4:20:11,  1.36s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-150.00max_-205.48avg_-238.00min__1623679205.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 24%|##3       | 3549/15000 [32:36<2:01:14,  1.57episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-147.00max_-204.48avg_-225.00min__1623679244.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 24%|##3       | 3599/15000 [33:04<2:07:22,  1.49episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-160.00max_-203.52avg_-274.00min__1623679273.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 24%|##4       | 3649/15000 [33:44<1:59:33,  1.58episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-206.26avg_-235.00min__1623679312.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 25%|##4       | 3699/15000 [34:25<1:46:21,  1.77episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-203.46avg_-244.00min__1623679355.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 25%|##4       | 3749/15000 [35:19<4:19:20,  1.38s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-151.00max_-209.70avg_-272.00min__1623679408.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 25%|##5       | 3799/15000 [36:03<1:02:17,  3.00episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-209.62avg_-331.00min__1623679452.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 26%|##5       | 3849/15000 [36:53<5:15:34,  1.70s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-210.30avg_-272.00min__1623679501.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 26%|##5       | 3899/15000 [37:24<1:29:03,  2.08episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-157.00max_-205.10avg_-246.00min__1623679537.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 26%|##6       | 3949/15000 [38:08<2:40:49,  1.15episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-204.46avg_-233.00min__1623679577.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 27%|##6       | 3998/15000 [38:49<2:04:22,  1.47episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___201.00max_-187.98avg_-240.00min__1623679617.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 27%|##6       | 4048/15000 [39:33<1:47:43,  1.69episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-207.80avg_-251.00min__1623679661.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 27%|##7       | 4099/15000 [40:20<3:29:56,  1.16s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-209.80avg_-300.00min__1623679711.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 28%|##7       | 4149/15000 [41:11<1:31:45,  1.97episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-153.00max_-209.56avg_-261.00min__1623679760.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 28%|##7       | 4199/15000 [41:58<1:54:09,  1.58episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-209.34avg_-253.00min__1623679807.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 28%|##8       | 4249/15000 [42:36<2:07:46,  1.40episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-203.14avg_-252.00min__1623679844.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 29%|##8       | 4299/15000 [43:17<2:34:04,  1.16episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-159.00max_-207.66avg_-296.00min__1623679886.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 29%|##8       | 4349/15000 [44:04<5:05:03,  1.72s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-201.16avg_-256.00min__1623679933.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 29%|##9       | 4399/15000 [44:47<3:00:31,  1.02s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-207.60avg_-233.00min__1623679976.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 30%|##9       | 4449/15000 [45:37<3:38:05,  1.24s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-180.00max_-208.60avg_-257.00min__1623680027.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 30%|##9       | 4499/15000 [46:25<2:39:11,  1.10episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-204.84avg_-238.00min__1623680074.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 30%|###       | 4548/15000 [46:56<2:49:29,  1.03episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-203.04avg_-238.00min__1623680105.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 31%|###       | 4599/15000 [47:39<1:48:33,  1.60episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-208.84avg_-241.00min__1623680150.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 31%|###       | 4649/15000 [48:26<1:04:57,  2.66episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-209.56avg_-260.00min__1623680197.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 31%|###1      | 4699/15000 [49:33<4:02:30,  1.41s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-206.50avg_-286.00min__1623680261.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 32%|###1      | 4749/15000 [50:15<4:21:09,  1.53s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-207.26avg_-239.00min__1623680304.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 32%|###1      | 4798/15000 [51:04<2:27:42,  1.15episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-202.74avg_-281.00min__1623680352.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 32%|###2      | 4849/15000 [51:46<3:15:01,  1.15s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-204.46avg_-270.00min__1623680396.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 33%|###2      | 4899/15000 [52:23<1:13:01,  2.31episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-204.86avg_-255.00min__1623680433.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 33%|###2      | 4949/15000 [53:16<2:28:00,  1.13episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-145.00max_-206.16avg_-245.00min__1623680485.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 33%|###3      | 4999/15000 [54:00<2:05:52,  1.32episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-154.00max_-204.76avg_-243.00min__1623680529.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 34%|###3      | 5049/15000 [54:42<1:06:48,  2.48episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-205.14avg_-274.00min__1623680571.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 34%|###3      | 5099/15000 [55:25<2:59:24,  1.09s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-153.00max_-207.34avg_-300.00min__1623680614.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 34%|###4      | 5149/15000 [56:11<1:39:01,  1.66episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-208.56avg_-283.00min__1623680662.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 35%|###4      | 5198/15000 [56:56<2:08:50,  1.27episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-163.00max_-206.90avg_-302.00min__1623680705.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 35%|###4      | 5249/15000 [57:51<2:32:50,  1.06episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-206.36avg_-239.00min__1623680760.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 35%|###5      | 5299/15000 [58:54<1:58:25,  1.37episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-211.02avg_-268.00min__1623680823.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 36%|###5      | 5349/15000 [59:38<2:11:57,  1.22episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-203.70avg_-274.00min__1623680867.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 36%|###5      | 5399/15000 [1:00:20<2:07:34,  1.25episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-154.00max_-206.72avg_-244.00min__1623680910.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 36%|###6      | 5449/15000 [1:01:16<1:42:20,  1.56episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-147.00max_-208.68avg_-257.00min__1623680965.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 37%|###6      | 5499/15000 [1:01:51<2:00:05,  1.32episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-203.80avg_-258.00min__1623681000.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 37%|###6      | 5549/15000 [1:02:42<1:59:57,  1.31episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-194.00max_-208.40avg_-247.00min__1623681050.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 37%|###7      | 5599/15000 [1:03:21<1:27:37,  1.79episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-205.78avg_-243.00min__1623681093.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 38%|###7      | 5649/15000 [1:04:44<4:53:37,  1.88s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-213.34avg_-271.00min__1623681172.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 38%|###7      | 5699/15000 [1:05:52<3:59:27,  1.54s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-211.44avg_-307.00min__1623681242.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 38%|###8      | 5749/15000 [1:06:53<1:46:55,  1.44episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-207.48avg_-293.00min__1623681303.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 39%|###8      | 5799/15000 [1:07:58<1:54:12,  1.34episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-148.00max_-211.90avg_-279.00min__1623681367.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 39%|###8      | 5849/15000 [1:08:47<3:01:05,  1.19s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-149.00max_-206.10avg_-247.00min__1623681417.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 39%|###9      | 5899/15000 [1:09:45<2:18:50,  1.09episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-207.40avg_-275.00min__1623681473.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 40%|###9      | 5949/15000 [1:10:38<2:09:08,  1.17episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-206.98avg_-316.00min__1623681526.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 40%|###9      | 5999/15000 [1:11:35<2:44:50,  1.10s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-155.00max_-210.90avg_-292.00min__1623681584.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 40%|####      | 6049/15000 [1:13:17<8:04:53,  3.25s/episodes] \"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-217.48avg_-384.00min__1623681687.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 41%|####      | 6099/15000 [1:14:49<4:03:53,  1.64s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-188.00max_-219.10avg_-335.00min__1623681778.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 41%|####      | 6148/15000 [1:16:06<4:02:44,  1.65s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___206.00max_-205.46avg_-295.00min__1623681855.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 41%|####1     | 6199/15000 [1:17:01<2:09:25,  1.13episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-152.00max_-207.14avg_-244.00min__1623681910.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 42%|####1     | 6248/15000 [1:18:18<10:22:33,  4.27s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-211.90avg_-334.00min__1623681989.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 42%|####1     | 6298/15000 [1:19:19<1:54:41,  1.26episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___170.00max_-202.68avg_-267.00min__1623682048.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 42%|####2     | 6349/15000 [1:20:04<2:09:49,  1.11episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-210.02avg_-273.00min__1623682093.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 43%|####2     | 6399/15000 [1:21:27<2:54:05,  1.21s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-154.00max_-212.96avg_-312.00min__1623682176.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 43%|####2     | 6449/15000 [1:22:36<4:11:46,  1.77s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-153.00max_-213.10avg_-364.00min__1623682244.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 43%|####3     | 6499/15000 [1:24:02<1:50:51,  1.28episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-213.44avg_-305.00min__1623682330.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 44%|####3     | 6548/15000 [1:24:58<1:49:37,  1.28episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-147.00max_-210.46avg_-274.00min__1623682387.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 44%|####3     | 6599/15000 [1:25:54<1:33:43,  1.49episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-153.00max_-207.46avg_-316.00min__1623682445.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 44%|####4     | 6649/15000 [1:26:56<1:10:18,  1.98episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-205.42avg_-249.00min__1623682504.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 45%|####4     | 6699/15000 [1:28:08<2:39:07,  1.15s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-209.04avg_-278.00min__1623682578.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 45%|####4     | 6749/15000 [1:29:13<2:59:07,  1.30s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-145.00max_-207.96avg_-258.00min__1623682642.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 45%|####5     | 6799/15000 [1:30:37<2:13:08,  1.03episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-150.00max_-214.28avg_-306.00min__1623682725.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 46%|####5     | 6849/15000 [1:31:35<2:43:01,  1.20s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-208.68avg_-246.00min__1623682785.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 46%|####5     | 6899/15000 [1:33:02<3:52:11,  1.72s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-147.00max_-215.14avg_-307.00min__1623682876.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 46%|####6     | 6948/15000 [1:34:22<3:39:24,  1.63s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-213.86avg_-357.00min__1623682951.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 47%|####6     | 6999/15000 [1:35:16<1:10:07,  1.90episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-208.38avg_-292.00min__1623683005.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 47%|####6     | 7048/15000 [1:36:12<2:08:50,  1.03episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-157.00max_-208.70avg_-266.00min__1623683061.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 47%|####7     | 7099/15000 [1:37:06<2:46:12,  1.26s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-206.30avg_-242.00min__1623683114.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 48%|####7     | 7149/15000 [1:38:16<2:54:54,  1.34s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-149.00max_-210.44avg_-255.00min__1623683184.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 48%|####7     | 7199/15000 [1:39:39<3:50:39,  1.77s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-211.04avg_-295.00min__1623683269.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 48%|####8     | 7249/15000 [1:40:37<1:32:16,  1.40episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-207.98avg_-265.00min__1623683327.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 49%|####8     | 7299/15000 [1:41:26<3:11:25,  1.49s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-202.56avg_-230.00min__1623683375.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 49%|####8     | 7349/15000 [1:42:26<1:47:20,  1.19episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-210.50avg_-283.00min__1623683438.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 49%|####9     | 7399/15000 [1:43:50<6:37:18,  3.14s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-212.98avg_-265.00min__1623683521.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 50%|####9     | 7449/15000 [1:45:04<3:47:27,  1.81s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___209.00max_-200.74avg_-261.00min__1623683592.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 50%|####9     | 7498/15000 [1:46:33<3:30:40,  1.68s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___182.00max_-209.98avg_-313.00min__1623683683.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 50%|#####     | 7549/15000 [1:47:41<5:54:04,  2.85s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-208.12avg_-330.00min__1623683750.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 51%|#####     | 7598/15000 [1:49:10<2:26:26,  1.19s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-216.98avg_-333.00min__1623683839.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 51%|#####     | 7649/15000 [1:50:14<2:07:54,  1.04s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-208.50avg_-263.00min__1623683907.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 51%|#####1    | 7699/15000 [1:51:38<2:00:36,  1.01episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-211.40avg_-314.00min__1623683987.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 52%|#####1    | 7749/15000 [1:53:04<1:27:01,  1.39episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___191.00max_-203.28avg_-264.00min__1623684073.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 52%|#####1    | 7799/15000 [1:54:20<4:03:08,  2.03s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___194.00max_-199.86avg_-334.00min__1623684149.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 52%|#####2    | 7849/15000 [1:55:38<4:52:17,  2.45s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___206.00max_-202.44avg_-304.00min__1623684226.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 53%|#####2    | 7899/15000 [1:56:56<1:25:02,  1.39episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-155.00max_-213.64avg_-284.00min__1623684306.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 53%|#####2    | 7949/15000 [1:58:01<2:15:58,  1.16s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-210.24avg_-265.00min__1623684370.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 53%|#####3    | 7999/15000 [1:59:29<2:17:01,  1.17s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-150.00max_-214.76avg_-481.00min__1623684457.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 54%|#####3    | 8049/15000 [2:00:54<2:15:56,  1.17s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-150.00max_-214.56avg_-278.00min__1623684542.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 54%|#####3    | 8099/15000 [2:02:05<2:36:20,  1.36s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-175.00max_-211.20avg_-267.00min__1623684615.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 54%|#####4    | 8149/15000 [2:03:18<3:23:59,  1.79s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-159.00max_-208.14avg_-264.00min__1623684686.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 55%|#####4    | 8199/15000 [2:04:25<2:18:33,  1.22s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-150.00max_-209.70avg_-267.00min__1623684755.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 55%|#####4    | 8249/15000 [2:05:44<2:38:51,  1.41s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-210.12avg_-308.00min__1623684836.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 55%|#####5    | 8299/15000 [2:07:17<2:42:06,  1.45s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-198.00max_-217.34avg_-312.00min__1623684926.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 56%|#####5    | 8349/15000 [2:08:37<3:24:22,  1.84s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-145.00max_-208.76avg_-266.00min__1623685005.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 56%|#####5    | 8399/15000 [2:09:37<1:31:50,  1.20episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-210.78avg_-267.00min__1623685068.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 56%|#####6    | 8449/15000 [2:11:20<6:33:29,  3.60s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-217.20avg_-301.00min__1623685169.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 57%|#####6    | 8499/15000 [2:13:00<5:31:03,  3.06s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-158.00max_-220.72avg_-361.00min__1623685269.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 57%|#####6    | 8549/15000 [2:14:32<7:48:45,  4.36s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-216.30avg_-334.00min__1623685361.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 57%|#####7    | 8598/15000 [2:15:41<2:11:06,  1.23s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-155.00max_-211.56avg_-284.00min__1623685430.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 58%|#####7    | 8649/15000 [2:16:40<2:51:34,  1.62s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-147.00max_-207.16avg_-259.00min__1623685489.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 58%|#####7    | 8699/15000 [2:17:45<3:06:55,  1.78s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-208.78avg_-255.00min__1623685554.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 58%|#####8    | 8749/15000 [2:18:56<3:52:15,  2.23s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-212.06avg_-275.00min__1623685624.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 59%|#####8    | 8799/15000 [2:20:50<4:09:32,  2.41s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-149.00max_-215.52avg_-303.00min__1623685738.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 59%|#####8    | 8849/15000 [2:22:14<4:58:59,  2.92s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-215.86avg_-293.00min__1623685826.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 59%|#####9    | 8898/15000 [2:23:40<1:49:47,  1.08s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-161.00max_-211.54avg_-269.00min__1623685911.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 60%|#####9    | 8949/15000 [2:25:00<3:16:53,  1.95s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-209.90avg_-300.00min__1623685991.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 60%|#####9    | 8998/15000 [2:26:34<2:12:45,  1.33s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-210.92avg_-265.00min__1623686083.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 60%|######    | 9049/15000 [2:27:46<2:42:25,  1.64s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-145.00max_-208.18avg_-270.00min__1623686154.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 61%|######    | 9099/15000 [2:29:12<2:46:40,  1.69s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-196.00max_-214.94avg_-293.00min__1623686243.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 61%|######    | 9149/15000 [2:30:47<2:27:06,  1.51s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-213.36avg_-292.00min__1623686338.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 61%|######1   | 9199/15000 [2:32:14<1:20:57,  1.19episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-148.00max_-213.20avg_-337.00min__1623686423.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 62%|######1   | 9249/15000 [2:33:28<2:29:23,  1.56s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-206.96avg_-259.00min__1623686496.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 62%|######1   | 9299/15000 [2:34:34<1:45:25,  1.11s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-159.00max_-207.14avg_-246.00min__1623686562.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 62%|######2   | 9349/15000 [2:36:07<1:45:50,  1.12s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-197.00max_-215.40avg_-279.00min__1623686656.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 63%|######2   | 9399/15000 [2:37:32<2:46:34,  1.78s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-211.18avg_-317.00min__1623686742.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 63%|######2   | 9449/15000 [2:39:07<2:04:56,  1.35s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-166.00max_-215.18avg_-274.00min__1623686835.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 63%|######3   | 9499/15000 [2:40:21<1:58:19,  1.29s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-175.00max_-210.58avg_-246.00min__1623686912.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 64%|######3   | 9549/15000 [2:41:44<2:04:56,  1.38s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-150.00max_-210.02avg_-261.00min__1623686994.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 64%|######3   | 9599/15000 [2:43:30<4:09:35,  2.77s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-212.96avg_-315.00min__1623687098.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 64%|######4   | 9649/15000 [2:44:50<2:23:31,  1.61s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-210.60avg_-358.00min__1623687183.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 65%|######4   | 9699/15000 [2:46:17<1:47:31,  1.22s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-212.02avg_-321.00min__1623687266.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 65%|######4   | 9749/15000 [2:47:58<2:54:53,  2.00s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-214.68avg_-305.00min__1623687367.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 65%|######5   | 9799/15000 [2:49:20<2:37:02,  1.81s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-205.98avg_-269.00min__1623687450.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 66%|######5   | 9849/15000 [2:51:03<2:41:47,  1.88s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-159.00max_-213.46avg_-281.00min__1623687559.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 66%|######5   | 9899/15000 [2:52:42<2:07:47,  1.50s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-175.00max_-213.86avg_-280.00min__1623687651.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 66%|######6   | 9949/15000 [2:54:08<1:53:27,  1.35s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-151.00max_-212.04avg_-266.00min__1623687739.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 67%|######6   | 9999/15000 [2:55:38<2:36:16,  1.87s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-212.36avg_-276.00min__1623687829.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 67%|######6   | 10049/15000 [2:57:13<2:30:13,  1.82s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-149.00max_-213.32avg_-267.00min__1623687922.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 67%|######7   | 10099/15000 [2:58:47<4:30:23,  3.31s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___209.00max_-208.54avg_-297.00min__1623688017.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 68%|######7   | 10149/15000 [3:00:34<2:39:57,  1.98s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-218.66avg_-371.00min__1623688126.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 68%|######7   | 10199/15000 [3:02:05<2:24:44,  1.81s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-206.58avg_-252.00min__1623688215.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 68%|######8   | 10249/15000 [3:03:40<1:39:15,  1.25s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-210.82avg_-280.00min__1623688309.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 69%|######8   | 10299/15000 [3:04:45<1:08:12,  1.15episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-150.00max_-209.94avg_-281.00min__1623688383.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 69%|######8   | 10349/15000 [3:06:36<3:06:55,  2.41s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-213.84avg_-308.00min__1623688485.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 69%|######9   | 10399/15000 [3:08:34<3:32:17,  2.77s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-155.00max_-217.88avg_-280.00min__1623688605.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 70%|######9   | 10449/15000 [3:10:01<1:44:27,  1.38s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-212.80avg_-265.00min__1623688689.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 70%|######9   | 10499/15000 [3:11:39<4:17:37,  3.43s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-219.72avg_-448.00min__1623688787.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 70%|#######   | 10549/15000 [3:12:59<53:41,  1.38episodes/s]  \"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-214.42avg_-272.00min__1623688870.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 71%|#######   | 10599/15000 [3:14:41<2:29:48,  2.04s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-213.74avg_-312.00min__1623688969.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 71%|#######   | 10649/15000 [3:16:34<1:47:14,  1.48s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-149.00max_-217.58avg_-298.00min__1623689083.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 71%|#######1  | 10699/15000 [3:18:26<5:43:51,  4.80s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-216.90avg_-280.00min__1623689194.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 72%|#######1  | 10748/15000 [3:19:57<1:48:20,  1.53s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-151.00max_-214.94avg_-290.00min__1623689287.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 72%|#######1  | 10799/15000 [3:21:55<1:49:24,  1.56s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-199.00max_-221.26avg_-359.00min__1623689405.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 72%|#######2  | 10849/15000 [3:23:48<1:37:21,  1.41s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-148.00max_-213.24avg_-273.00min__1623689516.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 73%|#######2  | 10899/15000 [3:26:11<1:21:09,  1.19s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-161.00max_-223.26avg_-328.00min__1623689661.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 73%|#######2  | 10949/15000 [3:27:28<1:30:51,  1.35s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-210.00avg_-270.00min__1623689740.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 73%|#######3  | 10999/15000 [3:29:34<1:31:58,  1.38s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-156.00max_-217.92avg_-277.00min__1623689863.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 74%|#######3  | 11049/15000 [3:31:13<1:58:43,  1.80s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-216.38avg_-312.00min__1623689969.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 74%|#######3  | 11098/15000 [3:33:38<2:20:27,  2.16s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-151.00max_-222.52avg_-427.00min__1623690107.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 74%|#######4  | 11149/15000 [3:35:57<2:27:58,  2.31s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-153.00max_-226.62avg_-465.00min__1623690246.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 75%|#######4  | 11199/15000 [3:37:34<1:18:42,  1.24s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-213.80avg_-264.00min__1623690343.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 75%|#######4  | 11249/15000 [3:39:16<1:55:07,  1.84s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-178.00max_-215.48avg_-302.00min__1623690445.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 75%|#######5  | 11299/15000 [3:41:02<1:39:43,  1.62s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-213.64avg_-301.00min__1623690556.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 76%|#######5  | 11349/15000 [3:43:12<1:36:07,  1.58s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-219.20avg_-319.00min__1623690683.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 76%|#######5  | 11399/15000 [3:44:33<3:33:50,  3.56s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-212.64avg_-247.00min__1623690761.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 76%|#######6  | 11449/15000 [3:46:54<3:12:25,  3.25s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-145.00max_-218.98avg_-323.00min__1623690902.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 77%|#######6  | 11499/15000 [3:48:44<2:49:52,  2.91s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-160.00max_-216.82avg_-329.00min__1623691014.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 77%|#######6  | 11549/15000 [3:51:16<2:27:16,  2.56s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-152.00max_-226.20avg_-439.00min__1623691165.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 77%|#######7  | 11599/15000 [3:53:33<2:48:49,  2.98s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-223.32avg_-354.00min__1623691305.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 78%|#######7  | 11649/15000 [3:55:36<2:20:00,  2.51s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-219.16avg_-299.00min__1623691430.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 78%|#######7  | 11699/15000 [3:57:58<5:03:51,  5.52s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-148.00max_-223.20avg_-429.00min__1623691567.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 78%|#######8  | 11749/15000 [4:00:28<1:06:31,  1.23s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-225.30avg_-377.00min__1623691719.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 79%|#######8  | 11799/15000 [4:02:51<1:50:33,  2.07s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-169.00max_-224.22avg_-323.00min__1623691860.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 79%|#######8  | 11849/15000 [4:04:31<2:04:49,  2.38s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-213.86avg_-270.00min__1623691962.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 79%|#######9  | 11899/15000 [4:07:14<1:45:58,  2.05s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___179.00max_-216.82avg_-329.00min__1623692124.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 80%|#######9  | 11949/15000 [4:10:03<1:50:47,  2.18s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-154.00max_-226.12avg_-364.00min__1623692292.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 80%|#######9  | 11999/15000 [4:12:43<44:57,  1.11episodes/s]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-225.88avg_-339.00min__1623692454.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 80%|########  | 12049/15000 [4:15:23<4:27:35,  5.44s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-145.00max_-225.80avg_-323.00min__1623692612.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 81%|########  | 12099/15000 [4:17:20<1:31:52,  1.90s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-150.00max_-219.70avg_-324.00min__1623692740.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 81%|########  | 12149/15000 [4:19:32<2:29:04,  3.14s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-149.00max_-216.92avg_-298.00min__1623692860.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 81%|########1 | 12199/15000 [4:21:23<1:26:39,  1.86s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-213.92avg_-261.00min__1623692995.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 82%|########1 | 12249/15000 [4:23:56<1:24:06,  1.83s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-218.50avg_-407.00min__1623693124.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 82%|########1 | 12299/15000 [4:26:03<2:09:18,  2.87s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___151.00max_-211.62avg_-312.00min__1623693252.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 82%|########2 | 12349/15000 [4:28:37<3:31:26,  4.79s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-157.00max_-226.42avg_-315.00min__1623693408.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 83%|########2 | 12399/15000 [4:30:55<1:15:58,  1.75s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-152.00max_-222.70avg_-342.00min__1623693546.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 83%|########2 | 12449/15000 [4:33:07<2:10:36,  3.07s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-157.00max_-218.46avg_-384.00min__1623693675.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 83%|########3 | 12499/15000 [4:35:25<58:05,  1.39s/episodes]  \"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-181.00max_-224.98avg_-320.00min__1623693816.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 84%|########3 | 12549/15000 [4:37:19<1:32:58,  2.28s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-153.00max_-213.50avg_-367.00min__1623693928.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 84%|########3 | 12599/15000 [4:39:50<4:08:16,  6.20s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___199.00max_-214.76avg_-323.00min__1623694079.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 84%|########4 | 12649/15000 [4:42:06<1:53:57,  2.91s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___209.00max_-215.34avg_-328.00min__1623694229.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 85%|########4 | 12699/15000 [4:44:21<1:01:42,  1.61s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-215.42avg_-323.00min__1623694354.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 85%|########4 | 12749/15000 [4:46:23<1:18:04,  2.08s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-217.38avg_-276.00min__1623694476.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 85%|########5 | 12799/15000 [4:48:45<1:25:09,  2.32s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-141.00max_-221.74avg_-439.00min__1623694613.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 86%|########5 | 12849/15000 [4:51:39<1:09:41,  1.94s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-175.00max_-228.14avg_-374.00min__1623694793.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 86%|########5 | 12899/15000 [4:53:57<2:59:42,  5.13s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-165.00max_-221.06avg_-308.00min__1623694927.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 86%|########6 | 12949/15000 [4:56:29<2:31:54,  4.44s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___192.00max_-215.96avg_-385.00min__1623695081.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 87%|########6 | 12998/15000 [4:58:48<49:06,  1.47s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-150.00max_-218.66avg_-373.00min__1623695218.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 87%|########6 | 13049/15000 [5:00:39<2:01:43,  3.74s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-211.62avg_-246.00min__1623695329.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 87%|########7 | 13099/15000 [5:02:48<2:29:13,  4.71s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-218.46avg_-299.00min__1623695457.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 88%|########7 | 13149/15000 [5:05:44<3:09:34,  6.14s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-226.92avg_-380.00min__1623695638.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 88%|########7 | 13199/15000 [5:08:31<1:46:16,  3.54s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-224.04avg_-331.00min__1623695801.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 88%|########8 | 13249/15000 [5:10:41<1:04:59,  2.23s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-153.00max_-225.18avg_-448.00min__1623695935.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 89%|########8 | 13299/15000 [5:14:03<1:33:49,  3.31s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-176.00max_-236.16avg_-352.00min__1623696133.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 89%|########8 | 13349/15000 [5:15:47<39:10,  1.42s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-182.00max_-217.22avg_-317.00min__1623696238.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 89%|########9 | 13399/15000 [5:18:30<3:44:31,  8.41s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-173.00max_-222.70avg_-325.00min__1623696399.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 90%|########9 | 13449/15000 [5:20:56<42:13,  1.63s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-170.00max_-226.18avg_-370.00min__1623696544.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 90%|########9 | 13499/15000 [5:23:15<1:13:01,  2.92s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-145.00max_-222.44avg_-334.00min__1623696686.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 90%|######### | 13549/15000 [5:25:45<1:56:40,  4.82s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-156.00max_-219.32avg_-309.00min__1623696835.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 91%|######### | 13599/15000 [5:28:54<1:45:25,  4.51s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___208.00max_-223.58avg_-335.00min__1623697034.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 91%|######### | 13649/15000 [5:31:55<1:12:16,  3.21s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-164.00max_-229.44avg_-328.00min__1623697207.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 91%|#########1| 13699/15000 [5:34:56<49:10,  2.27s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-221.42avg_-394.00min__1623697387.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 92%|#########1| 13749/15000 [5:38:15<1:31:56,  4.41s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-235.78avg_-400.00min__1623697584.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 92%|#########1| 13799/15000 [5:41:55<1:09:35,  3.48s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-170.00max_-233.74avg_-330.00min__1623697806.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 92%|#########2| 13849/15000 [5:44:39<1:57:06,  6.11s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-223.90avg_-313.00min__1623697969.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 93%|#########2| 13899/15000 [5:47:18<40:26,  2.20s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___146.00max_-214.88avg_-317.00min__1623698130.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 93%|#########2| 13949/15000 [5:50:36<1:48:18,  6.18s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-149.00max_-227.42avg_-367.00min__1623698327.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 93%|#########3| 13999/15000 [5:54:22<54:10,  3.25s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___196.00max_-223.26avg_-409.00min__1623698551.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 94%|#########3| 14049/15000 [5:56:50<36:59,  2.33s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___207.00max_-222.84avg_-445.00min__1623698699.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 94%|#########3| 14099/15000 [5:59:42<33:42,  2.25s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-149.00max_-224.72avg_-359.00min__1623698871.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 94%|#########4| 14149/15000 [6:03:12<51:48,  3.65s/episodes]  \"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___208.00max_-222.60avg_-353.00min__1623699081.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 95%|#########4| 14199/15000 [6:06:31<36:03,  2.70s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-140.00max_-227.02avg_-357.00min__1623699280.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 95%|#########4| 14249/15000 [6:09:35<30:33,  2.44s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-228.66avg_-374.00min__1623699466.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 95%|#########5| 14299/15000 [6:12:37<35:56,  3.08s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-150.00max_-229.30avg_-464.00min__1623699647.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 96%|#########5| 14349/15000 [6:16:19<38:45,  3.57s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-139.00max_-233.52avg_-379.00min__1623699872.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 96%|#########5| 14399/15000 [6:19:22<30:11,  3.01s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___204.00max_-226.74avg_-495.00min__1623700054.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 96%|#########6| 14449/15000 [6:22:39<52:48,  5.75s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256___207.00max_-218.90avg_-322.00min__1623700249.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 97%|#########6| 14499/15000 [6:25:27<22:43,  2.72s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-143.00max_-225.80avg_-433.00min__1623700417.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 97%|#########6| 14549/15000 [6:28:50<40:22,  5.37s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-149.00max_-235.16avg_-371.00min__1623700620.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 97%|#########7| 14599/15000 [6:32:17<20:34,  3.08s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-142.00max_-225.36avg_-336.00min__1623700828.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 98%|#########7| 14649/15000 [6:35:45<21:44,  3.72s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-201.00max_-234.02avg_-350.00min__1623701035.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 98%|#########7| 14699/15000 [6:39:04<29:09,  5.81s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-201.00max_-240.94avg_-525.00min__1623701246.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 98%|#########8| 14749/15000 [6:42:33<08:12,  1.96s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-147.00max_-234.98avg_-438.00min__1623701448.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 99%|#########8| 14799/15000 [6:45:33<08:55,  2.67s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-200.00max_-228.70avg_-335.00min__1623701624.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 99%|#########8| 14849/15000 [6:48:32<06:47,  2.70s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-164.00max_-224.32avg_-337.00min__1623701801.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\" 99%|#########9| 14899/15000 [6:51:51<07:05,  4.21s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-150.00max_-233.12avg_-385.00min__1623702004.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"100%|#########9| 14949/15000 [6:55:03<06:40,  7.85s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-146.00max_-228.46avg_-333.00min__1623702192.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"100%|#########9| 14999/15000 [6:58:08<00:01,  1.90s/episodes]\"],\"name\":\"stderr\"},{\"output_type\":\"stream\",\"text\":[\"INFO:tensorflow:Assets written to: models/2x256__-144.00max_-229.58avg_-358.00min__1623702377.model/assets\\n\"],\"name\":\"stdout\"},{\"output_type\":\"stream\",\"text\":[\"100%|##########| 15000/15000 [6:58:10<00:00,  1.67s/episodes]\\n\"],\"name\":\"stderr\"}]},{\"cell_type\":\"code\",\"metadata\":{\"id\":\"g4VodgzxtTi3\"},\"source\":[\"\"],\"execution_count\":null,\"outputs\":[]}]}\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IztkN6ezrqtK",
        "outputId": "b5c7f540-9115-4d57-d14f-acc0b694f8de"
      },
      "source": [
        "\n",
        "\n",
        "DISCOUNT = 0.99\n",
        "REPLAY_MEMORY_SIZE = 50_000  # How many last steps to keep for model training\n",
        "MIN_REPLAY_MEMORY_SIZE = 1_000  # Minimum number of steps in a memory to start training\n",
        "MINIBATCH_SIZE = 64  # How many steps (samples) to use for training\n",
        "UPDATE_TARGET_EVERY = 5  # Terminal states (end of episodes)\n",
        "MODEL_NAME = '2x256'\n",
        "MIN_REWARD = -200  # For model save\n",
        "MEMORY_FRACTION = 0.20\n",
        "\n",
        "# Environment settings\n",
        "EPISODES =15000\n",
        "\n",
        "# Exploration settings\n",
        "epsilon = 1  # not a constant, going to be decayed\n",
        "EPSILON_DECAY =0.99985\n",
        "MIN_EPSILON = 0.001\n",
        "\n",
        "#  Stats settings\n",
        "AGGREGATE_STATS_EVERY = 50 # episodes\n",
        "SHOW_PREVIEW = False\n",
        "\n",
        "lista = []\n",
        "\n",
        "class Blob:\n",
        "    \n",
        "\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "      \n",
        "        posicao = []\n",
        "        for x in range (10):\n",
        "            for y in range (10):\n",
        "                posicao.append((x,y))\n",
        "        calcada = [(0,1),(1,2),(2,2),(2,3),(2,5),(3,6),(4,2),(5,2),(6,3),(7,0),(7,1),(8,2),(4,1),(1,6),(2,6),\n",
        "                           (4,6),(5,6),(6,6),(7,6),(1,8),(2,8),(3,8),(4,8),(5,8),(8,8),(7,8),(0,9),(0,8),(8,9),(4,3),(4,4),(6,4)]\n",
        "        pedagio = [(6,8),(4,0),(8,5)]\n",
        "       \n",
        "        for coord in calcada:\n",
        "            if coord in posicao:\n",
        "                posicao.remove(coord)\n",
        "                \n",
        "        for coord in pedagio:\n",
        "            if coord in posicao:\n",
        "                posicao.remove(coord)\n",
        "                \n",
        "        origem_taxi = posicao[random.randint(0, len(posicao)-1)]\n",
        "        self.x = origem_taxi[0]\n",
        "        self.y = origem_taxi[1]\n",
        "        \n",
        "        posicao.remove(origem_taxi)\n",
        "        origem_passageiro = posicao[random.randint(0, len(posicao)-1)]\n",
        "        self.xP = origem_passageiro[0]\n",
        "        self.yP = origem_passageiro[1]\n",
        "        \n",
        "        posicao.remove(origem_passageiro)\n",
        "        origem_destino = posicao[random.randint(0, len(posicao)-1)]\n",
        "        self.xd = origem_destino[0]\n",
        "        self.yd = origem_destino[1]\n",
        "    \n",
        "    \n",
        "    def __str__(self):\n",
        "        return f\"Blob ({self.x}, {self.y})\"\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        return (self.x-other.x, self.y-other.y)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self.x == other.x and self.y == other.y\n",
        "      \n",
        "        #for i in calcada:\n",
        "            #return self.x == calcada[0] and self.y == calcada[1]\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    def action(self, choice):\n",
        "        '''\n",
        "        Gives us 9 total movement options. (0,1,2,3,4,5,6,7,8)\n",
        "        '''\n",
        "        if choice == 0:\n",
        "            self.move(x=1, y=1)\n",
        "        elif choice == 1:\n",
        "            self.move(x=-1, y=-1)\n",
        "        elif choice == 2:\n",
        "            self.move(x=-1, y=1)\n",
        "        elif choice == 3:\n",
        "            self.move(x=1, y=-1)\n",
        "        elif choice == 4:\n",
        "            self.move(x=1, y=0)\n",
        "        elif choice == 5:\n",
        "            self.move(x=-1, y=0)\n",
        "        elif choice == 6:\n",
        "            self.move(x=0, y=1)\n",
        "        elif choice == 7:\n",
        "            self.move(x=0, y=-1)\n",
        "        elif choice == 8:\n",
        "            self.move(x=0, y=0)\n",
        "\n",
        "    def move(self, x=False, y=False):\n",
        "\n",
        "        # If no value for x, move randomly\n",
        "        if not x:\n",
        "            self.x += x\n",
        "        else:\n",
        "            self.x += x\n",
        "\n",
        "        # If no value for y, move randomly\n",
        "        if not y:\n",
        "            self.y += y\n",
        "        else:\n",
        "            self.y += y\n",
        "\n",
        "        # If we are out of bounds, fix!\n",
        "        if self.x < 0:\n",
        "            self.x = 0\n",
        "        elif self.x > self.size-1:\n",
        "            self.x = self.size-1\n",
        "        if self.y < 0:\n",
        "            self.y = 0\n",
        "        elif self.y > self.size-1:\n",
        "            self.y = self.size-1\n",
        "\n",
        "\n",
        "class BlobEnv:\n",
        "    SIZE = 10\n",
        "    RETURN_IMAGES = True\n",
        "    MOVE_PENALTY = 1\n",
        "    ENEMY_PENALTY = 200\n",
        "    PASSAGEIRO_REWARD = 60\n",
        "    PEDAGIO_PENALTY = 5\n",
        "    DESTINO_REWARD = 150\n",
        "    OBSERVATION_SPACE_VALUES = (SIZE, SIZE, 3)  # 4\n",
        "    ACTION_SPACE_SIZE = 9\n",
        "    PLAYER_N = 1  # player key in dict\n",
        "    PASSAGEIRO_N = 2  # passageiro key in dict\n",
        "    ENEMY_N = 3  # enemy key in dict\n",
        "    PEDAGIO_N = 4\n",
        "    DESTINO_N = 5\n",
        "    \n",
        "    # the dict! (colors)\n",
        "    d = {1: (0, 255, 255),\n",
        "         2: (255, 255, 255),\n",
        "         3: (100, 100, 100),\n",
        "         4: (0,0,150),\n",
        "         5: (0,200,0)}\n",
        "\n",
        "    def reset(self):\n",
        "        \n",
        "        self.player = Blob(self.SIZE)\n",
        "        self.passageiro = Blob(self.SIZE)\n",
        "        self.destino = Blob(self.SIZE)\n",
        "        \n",
        "        while self.passageiro == self.player:\n",
        "            self.passageiro = Blob(self.SIZE)\n",
        "            \n",
        "        while self.destino == self.player:\n",
        "            self.destino = Blob(self.SIZE)\n",
        "    \n",
        "        #self.enemy = Blob(self.SIZE)\n",
        "       # while self.enemy == self.player and self.enemy == self.passageiro :\n",
        "         #   self.enemy = Blob(self.SIZE)\n",
        "    \n",
        "\n",
        "        self.episode_step = 0\n",
        "\n",
        "        if self.RETURN_IMAGES:\n",
        "            observation = np.array(self.get_image())\n",
        "        else:\n",
        "            observation = (self.player-self.passageiro) + (self.player-self.enemy)\n",
        "        return observation\n",
        "    \n",
        "    def step(self, action):\n",
        "        \n",
        "        self.episode_step += 1\n",
        "        self.player.action(action)\n",
        "        \n",
        "        \n",
        "\n",
        "        if self.RETURN_IMAGES:\n",
        "            new_observation = np.array(self.get_image())\n",
        "        else:\n",
        "            new_observation = (self.player-self.passageiro) + (self.player-self.enemy)\n",
        "        \n",
        "        calcada = [(0,1),(1,2),(2,2),(2,3),(2,5),(3,6),(4,2),(5,2),(6,3),(7,0),(7,1),(8,2),(4,1),(1,6),(2,6),\n",
        "                           (4,6),(5,6),(6,6),(7,6),(1,8),(3,8),(4,8),(5,8),(8,8),(7,8),(0,9),(0,8),(8,9),(8,5),(4,3),(4,4),(6,4)]\n",
        "        \n",
        "        global lista\n",
        "    \n",
        "    \n",
        "        if self.player.x == self.destino.xd and self.player.y == self.destino.yd and len(lista)>0 :\n",
        "            reward = self.DESTINO_REWARD\n",
        "            \n",
        "        elif self.player.x == self.destino.xd and self.player.y == self.destino.yd and len(lista)==0 :\n",
        "            reward = -self.MOVE_PENALTY\n",
        "        \n",
        "        elif (self.player.x == 0 and self.player.y == 1) | (self.player.x == 1 and self.player.y == 2) | (self.player.x == 2 and self.player.y == 2) | (self.player.x == 2 and self.player.y == 3) |(self.player.x == 2 and self.player.y == 5) | (self.player.x == 3 and self.player.y == 6):\n",
        "            reward = -self.ENEMY_PENALTY\n",
        "            \n",
        "        elif (self.player.x == 4 and self.player.y == 2) | (self.player.x == 5 and self.player.y == 2) | (self.player.x == 6 and self.player.y == 3) | (self.player.x == 7 and self.player.y == 0) |(self.player.x == 7 and self.player.y == 1) | (self.player.x == 8 and self.player.y == 2):\n",
        "            reward = -self.ENEMY_PENALTY\n",
        "            \n",
        "        elif (self.player.x == 4 and self.player.y == 1) | (self.player.x == 1 and self.player.y == 6) | (self.player.x == 2 and self.player.y == 6) | (self.player.x == 4 and self.player.y == 6) |(self.player.x == 5 and self.player.y == 6) | (self.player.x == 6 and self.player.y == 6):\n",
        "            reward = -self.ENEMY_PENALTY\n",
        "            \n",
        "        elif (self.player.x == 7 and self.player.y == 6) | (self.player.x == 1 and self.player.y == 8) | (self.player.x == 3 and self.player.y == 8) | (self.player.x == 4 and self.player.y == 8) |(self.player.x == 5 and self.player.y == 8) | (self.player.x == 8 and self.player.y == 8):\n",
        "            reward = -self.ENEMY_PENALTY\n",
        "            \n",
        "        elif (self.player.x == 7 and self.player.y == 8) | (self.player.x == 0 and self.player.y == 9) | (self.player.x == 0 and self.player.y == 8) | (self.player.x == 8 and self.player.y == 9) | (self.player.x == 4 and self.player.y == 3):\n",
        "            reward = -self.ENEMY_PENALTY\n",
        "            \n",
        "        elif (self.player.x == 4 and self.player.y == 4) | (self.player.x == 6 and self.player.y == 4):\n",
        "            reward = -self.ENEMY_PENALTY\n",
        "        \n",
        "        elif self.player.x == self.passageiro.xP and self.player.y == self.passageiro.yP and len(lista)==0:\n",
        "            reward = self.PASSAGEIRO_REWARD\n",
        "            lista.append(1)\n",
        "            \n",
        "        elif (self.player.x == 6 and self.player.y == 8) | (self.player.x == 4 and self.player.y == 0) | (self.player.x == 8 and self.player.y == 5):\n",
        "            reward = -self.PEDAGIO_PENALTY\n",
        "        \n",
        "        else:\n",
        "            reward = -self.MOVE_PENALTY\n",
        "\n",
        "        done = False\n",
        "        \n",
        "        if reward == self.DESTINO_REWARD or reward == -self.ENEMY_PENALTY or self.episode_step >= 200:\n",
        "            lista.clear()\n",
        "            done = True\n",
        "        \n",
        "        #print(lista)\n",
        "        \n",
        "        return new_observation, reward, done\n",
        "\n",
        "\n",
        "    \n",
        "    def render(self):\n",
        "        img = self.get_image()\n",
        "        img = img.resize((10, 10),PIL.Image.NEAREST)  # resizing so we can see our agent in all its glory.\n",
        "        cv2.imshow(\"image\", np.array(img))  # show it!\n",
        "        cv2.waitKey(1)\n",
        "\n",
        "    # FOR CNN #\n",
        "    def get_image(self):\n",
        "        \n",
        "        calcada = [(0,1),(1,2),(2,2),(2,3),(2,5),(3,6),(4,2),(5,2),(6,3),(7,0),(7,1),(8,2),(4,1),(1,6),(2,6),\n",
        "                           (4,6),(5,6),(6,6),(7,6),(1,8),(3,8),(4,8),(5,8),(8,8),(7,8),(0,9),(0,8),(8,9),(4,3),(4,4),(6,4)]\n",
        "        pedagio = [(6,8),(4,0),(8,5)]\n",
        "    \n",
        "        env = np.zeros((self.SIZE, self.SIZE, 3), dtype=np.uint8)  # starts an rbg of our size\n",
        "        #env[self.passageiro.x][self.passageiro.y] = self.d[self.passageiro_N]  # sets the passageiro location tile to green color\n",
        "        env[self.passageiro.xP][self.passageiro.yP] = self.d[self.PASSAGEIRO_N]  # sets the passageiro location tile to green color\n",
        "        for i in calcada:\n",
        "            env[i[0]][i[1]] = self.d[self.ENEMY_N]\n",
        "        env[self.player.x][self.player.y] = self.d[self.PLAYER_N]  # sets the player tile to blue\n",
        "       \n",
        "        for i in pedagio:\n",
        "            env[i[0]][i[1]] = self.d[self.PEDAGIO_N]\n",
        "            \n",
        "        env[self.destino.xd][self.destino.yd] = self.d[self.DESTINO_N]  # sets the passageiro location tile to green color\n",
        "     \n",
        "        img = Image.fromarray(env, 'RGB')  # reading to rgb. Apparently. Even tho color definitions are bgr. ???\n",
        "        return img\n",
        "\n",
        "\n",
        "env = BlobEnv()\n",
        "\n",
        "# For stats\n",
        "ep_rewards = [-200]\n",
        "\n",
        "# For more repetitive results\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "#tf.set_random_seed(1)\n",
        "\n",
        "# Memory fraction, used mostly when trai8ning multiple agents\n",
        "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=MEMORY_FRACTION)\n",
        "#backend.set_session(tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)))\n",
        "\n",
        "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=MEMORY_FRACTION)\n",
        "tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
        "  \n",
        "\n",
        "\n",
        "# Create models folder\n",
        "if not os.path.isdir('models'):\n",
        "    os.makedirs('models')\n",
        "\n",
        "\n",
        "# Own Tensorboard class\n",
        "class ModifiedTensorBoard(TensorBoard):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.step = 1\n",
        "        self.writer = tf.summary.create_file_writer(self.log_dir)\n",
        "        self._log_write_dir = self.log_dir\n",
        "\n",
        "    def set_model(self, model):\n",
        "        self.model = model\n",
        "\n",
        "        self._train_dir = os.path.join(self._log_write_dir, 'train')\n",
        "        self._train_step = self.model._train_counter\n",
        "\n",
        "        self._val_dir = os.path.join(self._log_write_dir, 'validation')\n",
        "        self._val_step = self.model._test_counter\n",
        "\n",
        "        self._should_write_train_graph = False\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.update_stats(**logs)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_train_end(self, _):\n",
        "        pass\n",
        "\n",
        "    def update_stats(self, **stats):\n",
        "        with self.writer.as_default():\n",
        "            for key, value in stats.items():\n",
        "                tf.summary.scalar(key, value, step = self.step)\n",
        "                self.writer.flush()                \n",
        "\n",
        "   \n",
        "        \n",
        "# Agent class\n",
        "class DQNAgent:\n",
        "    def __init__(self):\n",
        "\n",
        "        # Main model\n",
        "        self.model = self.create_model()\n",
        "\n",
        "        # Target network\n",
        "        self.target_model = self.create_model()\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "        # An array with last n steps for training\n",
        "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
        "\n",
        "        # Custom tensorboard object\n",
        "        self.tensorboard = ModifiedTensorBoard(log_dir=\"logs/fit/{}-{}\".format(MODEL_NAME, int(time.time())))\n",
        "\n",
        "        # Used to count when to update target network with main network's weights\n",
        "        self.target_update_counter = 0\n",
        "\n",
        "    def create_model(self):\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), input_shape=env.OBSERVATION_SPACE_VALUES))  # OBSERVATION_SPACE_VALUES = (10, 10, 3) a 10x10 RGB image.\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "        model.add(Dense(64))\n",
        "\n",
        "        model.add(Dense(env.ACTION_SPACE_SIZE, activation='linear'))  # ACTION_SPACE_SIZE = how many choices (9)\n",
        "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    # Adds step's data to a memory replay array\n",
        "    # (observation space, action, reward, new observation space, done)\n",
        "    def update_replay_memory(self, transition):\n",
        "        self.replay_memory.append(transition)\n",
        "\n",
        "    # Trains main network every step during episode\n",
        "    def train(self, terminal_state, step):\n",
        "\n",
        "        # Start training only if certain number of samples is already saved\n",
        "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
        "            return\n",
        "\n",
        "        # Get a minibatch of random samples from memory replay table\n",
        "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
        "\n",
        "        # Get current states from minibatch, then query NN model for Q values\n",
        "        current_states = np.array([transition[0] for transition in minibatch])/255\n",
        "        current_qs_list = self.model.predict(current_states)\n",
        "\n",
        "        # Get future states from minibatch, then query NN model for Q values\n",
        "        # When using target network, query it, otherwise main network should be queried\n",
        "        new_current_states = np.array([transition[3] for transition in minibatch])/255\n",
        "        future_qs_list = self.target_model.predict(new_current_states)\n",
        "\n",
        "        X = []\n",
        "        y = []\n",
        "\n",
        "        # Now we need to enumerate our batches\n",
        "        for index, (current_state, action, reward, new_current_state, done) in enumerate(minibatch):\n",
        "\n",
        "            # If not a terminal state, get new q from future states, otherwise set it to 0\n",
        "            # almost like with Q Learning, but we use just part of equation here\n",
        "            if not done:\n",
        "                max_future_q = np.max(future_qs_list[index])\n",
        "                new_q = reward + DISCOUNT * max_future_q\n",
        "            else:\n",
        "                new_q = reward\n",
        "\n",
        "            # Update Q value for given state\n",
        "            current_qs = current_qs_list[index]\n",
        "            current_qs[action] = new_q\n",
        "\n",
        "            # And append to our training data\n",
        "            X.append(current_state)\n",
        "            y.append(current_qs)\n",
        "\n",
        "        # Fit on all samples as one batch, log only on terminal state\n",
        "        self.model.fit(np.array(X)/255, np.array(y), batch_size=MINIBATCH_SIZE, verbose=0, shuffle=False, callbacks=[self.tensorboard] if terminal_state else None)\n",
        "\n",
        "        # Update target network counter every episode\n",
        "        if terminal_state:\n",
        "            self.target_update_counter += 1\n",
        "\n",
        "        # If counter reaches set value, update target network with weights of main network\n",
        "        if self.target_update_counter > UPDATE_TARGET_EVERY:\n",
        "            self.target_model.set_weights(self.model.get_weights())\n",
        "            self.target_update_counter = 0\n",
        "\n",
        "    # Queries main network for Q values given current observation space (environment state)\n",
        "    def get_qs(self, state):\n",
        "        return self.model.predict(np.array(state).reshape(-1, *state.shape)/255)[0]\n",
        "\n",
        "\n",
        "agent = DQNAgent()\n",
        "\n",
        "# Iterate over episodes\n",
        "for episode in tqdm(range(1, EPISODES + 1), ascii=True, unit='episodes'):\n",
        "\n",
        "    # Update tensorboard step every episode\n",
        "    agent.tensorboard.step = episode\n",
        "\n",
        "    # Restarting episode - reset episode reward and step number\n",
        "    episode_reward = 0\n",
        "    step = 1\n",
        "\n",
        "    # Reset environment and get initial state\n",
        "    current_state = env.reset()\n",
        "\n",
        "    # Reset flag and start iterating until episode ends\n",
        "    done = False\n",
        "    while not done:\n",
        "\n",
        "        # This part stays mostly the same, the change is to query a model for Q values\n",
        "        if np.random.random() > epsilon:\n",
        "            # Get action from Q table\n",
        "            action = np.argmax(agent.get_qs(current_state))\n",
        "        else:\n",
        "            # Get random action\n",
        "            action = np.random.randint(0, env.ACTION_SPACE_SIZE)\n",
        "\n",
        "        new_state, reward, done = env.step(action)\n",
        "\n",
        "        # Transform new continous state to new discrete state and count reward\n",
        "        episode_reward += reward\n",
        "\n",
        "        if SHOW_PREVIEW and not episode % AGGREGATE_STATS_EVERY:\n",
        "            env.render()\n",
        "\n",
        "        # Every step we update replay memory and train main network\n",
        "        agent.update_replay_memory((current_state, action, reward, new_state, done))\n",
        "        agent.train(done, step)\n",
        "\n",
        "        current_state = new_state\n",
        "        step += 1\n",
        "\n",
        "    # Append episode reward to a list and log stats (every given number of episodes)\n",
        "    ep_rewards.append(episode_reward)\n",
        "    if not episode % AGGREGATE_STATS_EVERY or episode == 1:\n",
        "        average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:])/len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
        "        min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
        "        max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
        "        agent.tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward, reward_max=max_reward, epsilon=epsilon)\n",
        "\n",
        "        # Save model, but only when min reward is greater or equal a set value\n",
        "        #if min_reward >= MIN_REWARD:\n",
        "        agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg_{min_reward:_>7.2f}min__{int(time.time())}.model')\n",
        "\n",
        "    # Decay epsilon\n",
        "    if epsilon > MIN_EPSILON:\n",
        "        epsilon *= EPSILON_DECAY\n",
        "        epsilon = max(MIN_EPSILON, epsilon)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "  0%|          | 0/15000 [00:00<?, ?episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-202.50avg_-205.00min__1623677288.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/15000 [00:06<26:54:21,  6.46s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-199.68avg_-230.00min__1623677294.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 62/15000 [00:22<14:42:46,  3.55s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___204.00max_-193.90avg_-240.00min__1623677310.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 139/15000 [00:23<7:11:54,  1.74s/episodes] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-149.00max_-204.70avg_-239.00min__1623677311.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|1         | 198/15000 [00:24<3:34:50,  1.15episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-148.00max_-202.66avg_-252.00min__1623677312.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|1         | 245/15000 [00:40<2:07:00,  1.94episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-201.82avg_-219.00min__1623677330.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|1         | 299/15000 [01:07<1:35:44,  2.56episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-147.00max_-204.00avg_-226.00min__1623677355.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|2         | 349/15000 [01:31<2:04:39,  1.96episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-201.86avg_-219.00min__1623677380.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|2         | 399/15000 [01:47<48:27,  5.02episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-201.28avg_-227.00min__1623677395.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|2         | 448/15000 [02:17<2:38:05,  1.53episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-176.00max_-204.28avg_-230.00min__1623677425.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|3         | 499/15000 [02:45<1:57:46,  2.05episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-203.56avg_-239.00min__1623677454.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|3         | 549/15000 [03:05<1:55:55,  2.08episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-202.72avg_-231.00min__1623677474.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|3         | 599/15000 [03:30<3:19:22,  1.20episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-198.16avg_-246.00min__1623677498.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|4         | 649/15000 [03:53<1:35:02,  2.52episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-200.68avg_-229.00min__1623677522.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|4         | 699/15000 [04:15<2:33:00,  1.56episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-201.98avg_-222.00min__1623677545.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|4         | 749/15000 [04:39<3:09:02,  1.26episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-204.42avg_-226.00min__1623677568.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|5         | 799/15000 [05:04<1:43:20,  2.29episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-204.10avg_-222.00min__1623677592.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  6%|5         | 849/15000 [05:30<1:14:18,  3.17episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-203.46avg_-231.00min__1623677619.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  6%|5         | 899/15000 [05:54<1:06:27,  3.54episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-153.00max_-202.84avg_-223.00min__1623677642.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  6%|6         | 949/15000 [06:24<2:31:49,  1.54episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-145.00max_-202.00avg_-233.00min__1623677672.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  7%|6         | 999/15000 [06:46<1:29:52,  2.60episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-200.40avg_-223.00min__1623677694.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  7%|6         | 1049/15000 [07:08<2:03:06,  1.89episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-203.94avg_-232.00min__1623677717.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  7%|7         | 1098/15000 [07:30<2:03:43,  1.87episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-154.00max_-202.84avg_-225.00min__1623677738.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|7         | 1149/15000 [08:02<1:32:50,  2.49episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-148.00max_-206.68avg_-251.00min__1623677771.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|7         | 1198/15000 [08:32<2:39:17,  1.44episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-204.94avg_-228.00min__1623677800.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|8         | 1249/15000 [08:53<2:05:01,  1.83episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-200.70avg_-228.00min__1623677822.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  9%|8         | 1299/15000 [09:16<1:32:12,  2.48episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-203.58avg_-222.00min__1623677844.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  9%|8         | 1349/15000 [09:40<1:59:20,  1.91episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-159.00max_-202.78avg_-215.00min__1623677868.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  9%|9         | 1399/15000 [10:06<1:55:13,  1.97episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-145.00max_-203.06avg_-236.00min__1623677895.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|9         | 1448/15000 [10:40<2:27:17,  1.53episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-155.00max_-204.80avg_-236.00min__1623677928.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|9         | 1499/15000 [11:05<1:17:01,  2.92episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-202.44avg_-227.00min__1623677953.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|#         | 1549/15000 [11:27<1:06:41,  3.36episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-149.00max_-202.96avg_-216.00min__1623677976.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 11%|#         | 1599/15000 [11:55<2:20:05,  1.59episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-200.02avg_-230.00min__1623678003.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 11%|#         | 1649/15000 [12:18<1:37:34,  2.28episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-202.76avg_-218.00min__1623678027.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 11%|#1        | 1699/15000 [12:47<1:39:53,  2.22episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-205.10avg_-226.00min__1623678056.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 12%|#1        | 1749/15000 [13:28<4:38:11,  1.26s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-209.26avg_-259.00min__1623678096.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 12%|#1        | 1799/15000 [13:52<1:40:30,  2.19episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___203.00max_-194.64avg_-222.00min__1623678121.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 12%|#2        | 1849/15000 [14:11<1:52:57,  1.94episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-199.18avg_-213.00min__1623678140.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|#2        | 1899/15000 [14:39<1:27:12,  2.50episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-204.66avg_-222.00min__1623678167.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|#2        | 1949/15000 [15:05<1:26:07,  2.53episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-201.96avg_-237.00min__1623678194.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|#3        | 1998/15000 [15:27<1:40:55,  2.15episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-148.00max_-201.16avg_-216.00min__1623678216.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|#3        | 2049/15000 [15:54<2:09:38,  1.67episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-153.00max_-203.78avg_-226.00min__1623678243.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|#3        | 2099/15000 [16:28<1:51:36,  1.93episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-145.00max_-205.38avg_-248.00min__1623678277.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|#4        | 2148/15000 [16:52<1:34:43,  2.26episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-204.04avg_-227.00min__1623678300.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|#4        | 2199/15000 [17:20<1:44:59,  2.03episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___197.00max_-196.26avg_-247.00min__1623678330.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|#4        | 2249/15000 [17:55<1:25:12,  2.49episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-202.32avg_-236.00min__1623678364.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|#5        | 2298/15000 [18:28<6:59:05,  1.98s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-202.88avg_-222.00min__1623678398.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 16%|#5        | 2349/15000 [18:58<1:43:30,  2.04episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-202.36avg_-264.00min__1623678426.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 16%|#5        | 2399/15000 [19:27<3:18:03,  1.06episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-195.86avg_-232.00min__1623678455.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 16%|#6        | 2449/15000 [20:05<3:49:00,  1.09s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-204.54avg_-237.00min__1623678493.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|#6        | 2498/15000 [20:32<1:48:22,  1.92episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-200.98avg_-228.00min__1623678521.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|#6        | 2549/15000 [21:09<3:55:56,  1.14s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___205.00max_-195.22avg_-226.00min__1623678558.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|#7        | 2598/15000 [21:46<3:41:41,  1.07s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-151.00max_-206.06avg_-271.00min__1623678594.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|#7        | 2649/15000 [22:13<1:27:39,  2.35episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-205.14avg_-270.00min__1623678622.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|#7        | 2699/15000 [22:46<1:24:06,  2.44episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-206.00avg_-234.00min__1623678657.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|#8        | 2749/15000 [23:21<2:03:37,  1.65episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-200.08avg_-233.00min__1623678690.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|#8        | 2799/15000 [23:50<1:50:32,  1.84episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-200.86avg_-224.00min__1623678718.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|#8        | 2848/15000 [24:22<3:24:09,  1.01s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-205.74avg_-232.00min__1623678751.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|#9        | 2899/15000 [24:56<1:48:04,  1.87episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-202.46avg_-244.00min__1623678787.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|#9        | 2949/15000 [25:28<1:32:23,  2.17episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-205.56avg_-236.00min__1623678816.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|#9        | 2999/15000 [25:57<2:17:58,  1.45episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-205.14avg_-221.00min__1623678846.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|##        | 3049/15000 [26:33<2:01:53,  1.63episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-152.00max_-205.76avg_-266.00min__1623678881.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|##        | 3099/15000 [27:15<2:20:05,  1.42episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-204.30avg_-265.00min__1623678924.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|##        | 3149/15000 [27:56<2:31:10,  1.31episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-151.00max_-207.40avg_-246.00min__1623678966.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|##1       | 3198/15000 [28:33<3:52:35,  1.18s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-204.26avg_-245.00min__1623679002.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|##1       | 3249/15000 [29:10<1:38:32,  1.99episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-205.66avg_-248.00min__1623679039.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|##1       | 3299/15000 [29:41<1:41:45,  1.92episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-203.38avg_-280.00min__1623679073.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|##2       | 3349/15000 [30:16<1:51:36,  1.74episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-206.62avg_-277.00min__1623679105.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|##2       | 3399/15000 [30:49<2:12:26,  1.46episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-206.10avg_-242.00min__1623679137.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|##2       | 3449/15000 [31:18<1:54:24,  1.68episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-156.00max_-204.38avg_-233.00min__1623679166.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|##3       | 3499/15000 [31:57<4:20:11,  1.36s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-150.00max_-205.48avg_-238.00min__1623679205.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 24%|##3       | 3549/15000 [32:36<2:01:14,  1.57episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-147.00max_-204.48avg_-225.00min__1623679244.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 24%|##3       | 3599/15000 [33:04<2:07:22,  1.49episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-160.00max_-203.52avg_-274.00min__1623679273.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 24%|##4       | 3649/15000 [33:44<1:59:33,  1.58episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-206.26avg_-235.00min__1623679312.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|##4       | 3699/15000 [34:25<1:46:21,  1.77episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-203.46avg_-244.00min__1623679355.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|##4       | 3749/15000 [35:19<4:19:20,  1.38s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-151.00max_-209.70avg_-272.00min__1623679408.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|##5       | 3799/15000 [36:03<1:02:17,  3.00episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-209.62avg_-331.00min__1623679452.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 26%|##5       | 3849/15000 [36:53<5:15:34,  1.70s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-210.30avg_-272.00min__1623679501.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 26%|##5       | 3899/15000 [37:24<1:29:03,  2.08episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-157.00max_-205.10avg_-246.00min__1623679537.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 26%|##6       | 3949/15000 [38:08<2:40:49,  1.15episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-204.46avg_-233.00min__1623679577.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|##6       | 3998/15000 [38:49<2:04:22,  1.47episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___201.00max_-187.98avg_-240.00min__1623679617.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|##6       | 4048/15000 [39:33<1:47:43,  1.69episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-207.80avg_-251.00min__1623679661.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|##7       | 4099/15000 [40:20<3:29:56,  1.16s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-209.80avg_-300.00min__1623679711.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 28%|##7       | 4149/15000 [41:11<1:31:45,  1.97episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-153.00max_-209.56avg_-261.00min__1623679760.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 28%|##7       | 4199/15000 [41:58<1:54:09,  1.58episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-209.34avg_-253.00min__1623679807.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 28%|##8       | 4249/15000 [42:36<2:07:46,  1.40episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-203.14avg_-252.00min__1623679844.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|##8       | 4299/15000 [43:17<2:34:04,  1.16episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-159.00max_-207.66avg_-296.00min__1623679886.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|##8       | 4349/15000 [44:04<5:05:03,  1.72s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-201.16avg_-256.00min__1623679933.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|##9       | 4399/15000 [44:47<3:00:31,  1.02s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-207.60avg_-233.00min__1623679976.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|##9       | 4449/15000 [45:37<3:38:05,  1.24s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-180.00max_-208.60avg_-257.00min__1623680027.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|##9       | 4499/15000 [46:25<2:39:11,  1.10episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-204.84avg_-238.00min__1623680074.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|###       | 4548/15000 [46:56<2:49:29,  1.03episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-203.04avg_-238.00min__1623680105.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 31%|###       | 4599/15000 [47:39<1:48:33,  1.60episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-208.84avg_-241.00min__1623680150.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 31%|###       | 4649/15000 [48:26<1:04:57,  2.66episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-209.56avg_-260.00min__1623680197.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 31%|###1      | 4699/15000 [49:33<4:02:30,  1.41s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-206.50avg_-286.00min__1623680261.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 32%|###1      | 4749/15000 [50:15<4:21:09,  1.53s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-207.26avg_-239.00min__1623680304.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 32%|###1      | 4798/15000 [51:04<2:27:42,  1.15episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-202.74avg_-281.00min__1623680352.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 32%|###2      | 4849/15000 [51:46<3:15:01,  1.15s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-204.46avg_-270.00min__1623680396.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|###2      | 4899/15000 [52:23<1:13:01,  2.31episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-204.86avg_-255.00min__1623680433.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|###2      | 4949/15000 [53:16<2:28:00,  1.13episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-145.00max_-206.16avg_-245.00min__1623680485.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|###3      | 4999/15000 [54:00<2:05:52,  1.32episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-154.00max_-204.76avg_-243.00min__1623680529.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 34%|###3      | 5049/15000 [54:42<1:06:48,  2.48episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-205.14avg_-274.00min__1623680571.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 34%|###3      | 5099/15000 [55:25<2:59:24,  1.09s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-153.00max_-207.34avg_-300.00min__1623680614.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 34%|###4      | 5149/15000 [56:11<1:39:01,  1.66episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-208.56avg_-283.00min__1623680662.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|###4      | 5198/15000 [56:56<2:08:50,  1.27episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-163.00max_-206.90avg_-302.00min__1623680705.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|###4      | 5249/15000 [57:51<2:32:50,  1.06episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-206.36avg_-239.00min__1623680760.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|###5      | 5299/15000 [58:54<1:58:25,  1.37episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-211.02avg_-268.00min__1623680823.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|###5      | 5349/15000 [59:38<2:11:57,  1.22episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-203.70avg_-274.00min__1623680867.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|###5      | 5399/15000 [1:00:20<2:07:34,  1.25episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-154.00max_-206.72avg_-244.00min__1623680910.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|###6      | 5449/15000 [1:01:16<1:42:20,  1.56episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-147.00max_-208.68avg_-257.00min__1623680965.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|###6      | 5499/15000 [1:01:51<2:00:05,  1.32episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-203.80avg_-258.00min__1623681000.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|###6      | 5549/15000 [1:02:42<1:59:57,  1.31episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-194.00max_-208.40avg_-247.00min__1623681050.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|###7      | 5599/15000 [1:03:21<1:27:37,  1.79episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-205.78avg_-243.00min__1623681093.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 38%|###7      | 5649/15000 [1:04:44<4:53:37,  1.88s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-213.34avg_-271.00min__1623681172.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 38%|###7      | 5699/15000 [1:05:52<3:59:27,  1.54s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-211.44avg_-307.00min__1623681242.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 38%|###8      | 5749/15000 [1:06:53<1:46:55,  1.44episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-207.48avg_-293.00min__1623681303.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 39%|###8      | 5799/15000 [1:07:58<1:54:12,  1.34episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-148.00max_-211.90avg_-279.00min__1623681367.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 39%|###8      | 5849/15000 [1:08:47<3:01:05,  1.19s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-149.00max_-206.10avg_-247.00min__1623681417.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 39%|###9      | 5899/15000 [1:09:45<2:18:50,  1.09episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-207.40avg_-275.00min__1623681473.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|###9      | 5949/15000 [1:10:38<2:09:08,  1.17episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-206.98avg_-316.00min__1623681526.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|###9      | 5999/15000 [1:11:35<2:44:50,  1.10s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-155.00max_-210.90avg_-292.00min__1623681584.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|####      | 6049/15000 [1:13:17<8:04:53,  3.25s/episodes] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-217.48avg_-384.00min__1623681687.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 41%|####      | 6099/15000 [1:14:49<4:03:53,  1.64s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-188.00max_-219.10avg_-335.00min__1623681778.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 41%|####      | 6148/15000 [1:16:06<4:02:44,  1.65s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___206.00max_-205.46avg_-295.00min__1623681855.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 41%|####1     | 6199/15000 [1:17:01<2:09:25,  1.13episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-152.00max_-207.14avg_-244.00min__1623681910.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42%|####1     | 6248/15000 [1:18:18<10:22:33,  4.27s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-211.90avg_-334.00min__1623681989.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42%|####1     | 6298/15000 [1:19:19<1:54:41,  1.26episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___170.00max_-202.68avg_-267.00min__1623682048.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42%|####2     | 6349/15000 [1:20:04<2:09:49,  1.11episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-210.02avg_-273.00min__1623682093.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|####2     | 6399/15000 [1:21:27<2:54:05,  1.21s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-154.00max_-212.96avg_-312.00min__1623682176.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|####2     | 6449/15000 [1:22:36<4:11:46,  1.77s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-153.00max_-213.10avg_-364.00min__1623682244.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|####3     | 6499/15000 [1:24:02<1:50:51,  1.28episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-213.44avg_-305.00min__1623682330.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|####3     | 6548/15000 [1:24:58<1:49:37,  1.28episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-147.00max_-210.46avg_-274.00min__1623682387.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|####3     | 6599/15000 [1:25:54<1:33:43,  1.49episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-153.00max_-207.46avg_-316.00min__1623682445.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|####4     | 6649/15000 [1:26:56<1:10:18,  1.98episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-205.42avg_-249.00min__1623682504.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|####4     | 6699/15000 [1:28:08<2:39:07,  1.15s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-209.04avg_-278.00min__1623682578.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|####4     | 6749/15000 [1:29:13<2:59:07,  1.30s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-145.00max_-207.96avg_-258.00min__1623682642.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|####5     | 6799/15000 [1:30:37<2:13:08,  1.03episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-150.00max_-214.28avg_-306.00min__1623682725.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 46%|####5     | 6849/15000 [1:31:35<2:43:01,  1.20s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-208.68avg_-246.00min__1623682785.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 46%|####5     | 6899/15000 [1:33:02<3:52:11,  1.72s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-147.00max_-215.14avg_-307.00min__1623682876.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 46%|####6     | 6948/15000 [1:34:22<3:39:24,  1.63s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-213.86avg_-357.00min__1623682951.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 47%|####6     | 6999/15000 [1:35:16<1:10:07,  1.90episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-208.38avg_-292.00min__1623683005.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 47%|####6     | 7048/15000 [1:36:12<2:08:50,  1.03episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-157.00max_-208.70avg_-266.00min__1623683061.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 47%|####7     | 7099/15000 [1:37:06<2:46:12,  1.26s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-206.30avg_-242.00min__1623683114.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|####7     | 7149/15000 [1:38:16<2:54:54,  1.34s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-149.00max_-210.44avg_-255.00min__1623683184.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|####7     | 7199/15000 [1:39:39<3:50:39,  1.77s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-211.04avg_-295.00min__1623683269.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|####8     | 7249/15000 [1:40:37<1:32:16,  1.40episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-207.98avg_-265.00min__1623683327.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 49%|####8     | 7299/15000 [1:41:26<3:11:25,  1.49s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-202.56avg_-230.00min__1623683375.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 49%|####8     | 7349/15000 [1:42:26<1:47:20,  1.19episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-210.50avg_-283.00min__1623683438.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 49%|####9     | 7399/15000 [1:43:50<6:37:18,  3.14s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-212.98avg_-265.00min__1623683521.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|####9     | 7449/15000 [1:45:04<3:47:27,  1.81s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___209.00max_-200.74avg_-261.00min__1623683592.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|####9     | 7498/15000 [1:46:33<3:30:40,  1.68s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___182.00max_-209.98avg_-313.00min__1623683683.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|#####     | 7549/15000 [1:47:41<5:54:04,  2.85s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-208.12avg_-330.00min__1623683750.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 51%|#####     | 7598/15000 [1:49:10<2:26:26,  1.19s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-216.98avg_-333.00min__1623683839.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 51%|#####     | 7649/15000 [1:50:14<2:07:54,  1.04s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-208.50avg_-263.00min__1623683907.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 51%|#####1    | 7699/15000 [1:51:38<2:00:36,  1.01episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-211.40avg_-314.00min__1623683987.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|#####1    | 7749/15000 [1:53:04<1:27:01,  1.39episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___191.00max_-203.28avg_-264.00min__1623684073.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|#####1    | 7799/15000 [1:54:20<4:03:08,  2.03s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___194.00max_-199.86avg_-334.00min__1623684149.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|#####2    | 7849/15000 [1:55:38<4:52:17,  2.45s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___206.00max_-202.44avg_-304.00min__1623684226.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|#####2    | 7899/15000 [1:56:56<1:25:02,  1.39episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-155.00max_-213.64avg_-284.00min__1623684306.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|#####2    | 7949/15000 [1:58:01<2:15:58,  1.16s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-210.24avg_-265.00min__1623684370.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|#####3    | 7999/15000 [1:59:29<2:17:01,  1.17s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-150.00max_-214.76avg_-481.00min__1623684457.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 54%|#####3    | 8049/15000 [2:00:54<2:15:56,  1.17s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-150.00max_-214.56avg_-278.00min__1623684542.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 54%|#####3    | 8099/15000 [2:02:05<2:36:20,  1.36s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-175.00max_-211.20avg_-267.00min__1623684615.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 54%|#####4    | 8149/15000 [2:03:18<3:23:59,  1.79s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-159.00max_-208.14avg_-264.00min__1623684686.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|#####4    | 8199/15000 [2:04:25<2:18:33,  1.22s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-150.00max_-209.70avg_-267.00min__1623684755.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|#####4    | 8249/15000 [2:05:44<2:38:51,  1.41s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-210.12avg_-308.00min__1623684836.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|#####5    | 8299/15000 [2:07:17<2:42:06,  1.45s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-198.00max_-217.34avg_-312.00min__1623684926.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 56%|#####5    | 8349/15000 [2:08:37<3:24:22,  1.84s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-145.00max_-208.76avg_-266.00min__1623685005.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 56%|#####5    | 8399/15000 [2:09:37<1:31:50,  1.20episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-210.78avg_-267.00min__1623685068.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 56%|#####6    | 8449/15000 [2:11:20<6:33:29,  3.60s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-217.20avg_-301.00min__1623685169.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|#####6    | 8499/15000 [2:13:00<5:31:03,  3.06s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-158.00max_-220.72avg_-361.00min__1623685269.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|#####6    | 8549/15000 [2:14:32<7:48:45,  4.36s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-216.30avg_-334.00min__1623685361.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|#####7    | 8598/15000 [2:15:41<2:11:06,  1.23s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-155.00max_-211.56avg_-284.00min__1623685430.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 58%|#####7    | 8649/15000 [2:16:40<2:51:34,  1.62s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-147.00max_-207.16avg_-259.00min__1623685489.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 58%|#####7    | 8699/15000 [2:17:45<3:06:55,  1.78s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-208.78avg_-255.00min__1623685554.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 58%|#####8    | 8749/15000 [2:18:56<3:52:15,  2.23s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-212.06avg_-275.00min__1623685624.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 59%|#####8    | 8799/15000 [2:20:50<4:09:32,  2.41s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-149.00max_-215.52avg_-303.00min__1623685738.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 59%|#####8    | 8849/15000 [2:22:14<4:58:59,  2.92s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-215.86avg_-293.00min__1623685826.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 59%|#####9    | 8898/15000 [2:23:40<1:49:47,  1.08s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-161.00max_-211.54avg_-269.00min__1623685911.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|#####9    | 8949/15000 [2:25:00<3:16:53,  1.95s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-209.90avg_-300.00min__1623685991.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|#####9    | 8998/15000 [2:26:34<2:12:45,  1.33s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-210.92avg_-265.00min__1623686083.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|######    | 9049/15000 [2:27:46<2:42:25,  1.64s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-145.00max_-208.18avg_-270.00min__1623686154.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 61%|######    | 9099/15000 [2:29:12<2:46:40,  1.69s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-196.00max_-214.94avg_-293.00min__1623686243.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 61%|######    | 9149/15000 [2:30:47<2:27:06,  1.51s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-213.36avg_-292.00min__1623686338.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 61%|######1   | 9199/15000 [2:32:14<1:20:57,  1.19episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-148.00max_-213.20avg_-337.00min__1623686423.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 62%|######1   | 9249/15000 [2:33:28<2:29:23,  1.56s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-206.96avg_-259.00min__1623686496.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 62%|######1   | 9299/15000 [2:34:34<1:45:25,  1.11s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-159.00max_-207.14avg_-246.00min__1623686562.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 62%|######2   | 9349/15000 [2:36:07<1:45:50,  1.12s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-197.00max_-215.40avg_-279.00min__1623686656.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 63%|######2   | 9399/15000 [2:37:32<2:46:34,  1.78s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-211.18avg_-317.00min__1623686742.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 63%|######2   | 9449/15000 [2:39:07<2:04:56,  1.35s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-166.00max_-215.18avg_-274.00min__1623686835.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 63%|######3   | 9499/15000 [2:40:21<1:58:19,  1.29s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-175.00max_-210.58avg_-246.00min__1623686912.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|######3   | 9549/15000 [2:41:44<2:04:56,  1.38s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-150.00max_-210.02avg_-261.00min__1623686994.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|######3   | 9599/15000 [2:43:30<4:09:35,  2.77s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-212.96avg_-315.00min__1623687098.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|######4   | 9649/15000 [2:44:50<2:23:31,  1.61s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-210.60avg_-358.00min__1623687183.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|######4   | 9699/15000 [2:46:17<1:47:31,  1.22s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-212.02avg_-321.00min__1623687266.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|######4   | 9749/15000 [2:47:58<2:54:53,  2.00s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-214.68avg_-305.00min__1623687367.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|######5   | 9799/15000 [2:49:20<2:37:02,  1.81s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-205.98avg_-269.00min__1623687450.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 66%|######5   | 9849/15000 [2:51:03<2:41:47,  1.88s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-159.00max_-213.46avg_-281.00min__1623687559.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 66%|######5   | 9899/15000 [2:52:42<2:07:47,  1.50s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-175.00max_-213.86avg_-280.00min__1623687651.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 66%|######6   | 9949/15000 [2:54:08<1:53:27,  1.35s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-151.00max_-212.04avg_-266.00min__1623687739.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|######6   | 9999/15000 [2:55:38<2:36:16,  1.87s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-212.36avg_-276.00min__1623687829.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|######6   | 10049/15000 [2:57:13<2:30:13,  1.82s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-149.00max_-213.32avg_-267.00min__1623687922.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|######7   | 10099/15000 [2:58:47<4:30:23,  3.31s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___209.00max_-208.54avg_-297.00min__1623688017.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|######7   | 10149/15000 [3:00:34<2:39:57,  1.98s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-218.66avg_-371.00min__1623688126.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|######7   | 10199/15000 [3:02:05<2:24:44,  1.81s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-206.58avg_-252.00min__1623688215.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|######8   | 10249/15000 [3:03:40<1:39:15,  1.25s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-210.82avg_-280.00min__1623688309.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 69%|######8   | 10299/15000 [3:04:45<1:08:12,  1.15episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-150.00max_-209.94avg_-281.00min__1623688383.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 69%|######8   | 10349/15000 [3:06:36<3:06:55,  2.41s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-213.84avg_-308.00min__1623688485.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 69%|######9   | 10399/15000 [3:08:34<3:32:17,  2.77s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-155.00max_-217.88avg_-280.00min__1623688605.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|######9   | 10449/15000 [3:10:01<1:44:27,  1.38s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-212.80avg_-265.00min__1623688689.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|######9   | 10499/15000 [3:11:39<4:17:37,  3.43s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-219.72avg_-448.00min__1623688787.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|#######   | 10549/15000 [3:12:59<53:41,  1.38episodes/s]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-214.42avg_-272.00min__1623688870.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|#######   | 10599/15000 [3:14:41<2:29:48,  2.04s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-213.74avg_-312.00min__1623688969.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|#######   | 10649/15000 [3:16:34<1:47:14,  1.48s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-149.00max_-217.58avg_-298.00min__1623689083.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|#######1  | 10699/15000 [3:18:26<5:43:51,  4.80s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-216.90avg_-280.00min__1623689194.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|#######1  | 10748/15000 [3:19:57<1:48:20,  1.53s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-151.00max_-214.94avg_-290.00min__1623689287.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|#######1  | 10799/15000 [3:21:55<1:49:24,  1.56s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-199.00max_-221.26avg_-359.00min__1623689405.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|#######2  | 10849/15000 [3:23:48<1:37:21,  1.41s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-148.00max_-213.24avg_-273.00min__1623689516.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|#######2  | 10899/15000 [3:26:11<1:21:09,  1.19s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-161.00max_-223.26avg_-328.00min__1623689661.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|#######2  | 10949/15000 [3:27:28<1:30:51,  1.35s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-210.00avg_-270.00min__1623689740.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|#######3  | 10999/15000 [3:29:34<1:31:58,  1.38s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-156.00max_-217.92avg_-277.00min__1623689863.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 74%|#######3  | 11049/15000 [3:31:13<1:58:43,  1.80s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-216.38avg_-312.00min__1623689969.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 74%|#######3  | 11098/15000 [3:33:38<2:20:27,  2.16s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-151.00max_-222.52avg_-427.00min__1623690107.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 74%|#######4  | 11149/15000 [3:35:57<2:27:58,  2.31s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-153.00max_-226.62avg_-465.00min__1623690246.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|#######4  | 11199/15000 [3:37:34<1:18:42,  1.24s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-213.80avg_-264.00min__1623690343.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|#######4  | 11249/15000 [3:39:16<1:55:07,  1.84s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-178.00max_-215.48avg_-302.00min__1623690445.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|#######5  | 11299/15000 [3:41:02<1:39:43,  1.62s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-213.64avg_-301.00min__1623690556.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 76%|#######5  | 11349/15000 [3:43:12<1:36:07,  1.58s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-219.20avg_-319.00min__1623690683.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 76%|#######5  | 11399/15000 [3:44:33<3:33:50,  3.56s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-212.64avg_-247.00min__1623690761.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 76%|#######6  | 11449/15000 [3:46:54<3:12:25,  3.25s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-145.00max_-218.98avg_-323.00min__1623690902.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|#######6  | 11499/15000 [3:48:44<2:49:52,  2.91s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-160.00max_-216.82avg_-329.00min__1623691014.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|#######6  | 11549/15000 [3:51:16<2:27:16,  2.56s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-152.00max_-226.20avg_-439.00min__1623691165.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|#######7  | 11599/15000 [3:53:33<2:48:49,  2.98s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-223.32avg_-354.00min__1623691305.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 78%|#######7  | 11649/15000 [3:55:36<2:20:00,  2.51s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-219.16avg_-299.00min__1623691430.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 78%|#######7  | 11699/15000 [3:57:58<5:03:51,  5.52s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-148.00max_-223.20avg_-429.00min__1623691567.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 78%|#######8  | 11749/15000 [4:00:28<1:06:31,  1.23s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-225.30avg_-377.00min__1623691719.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|#######8  | 11799/15000 [4:02:51<1:50:33,  2.07s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-169.00max_-224.22avg_-323.00min__1623691860.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|#######8  | 11849/15000 [4:04:31<2:04:49,  2.38s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-213.86avg_-270.00min__1623691962.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|#######9  | 11899/15000 [4:07:14<1:45:58,  2.05s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___179.00max_-216.82avg_-329.00min__1623692124.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|#######9  | 11949/15000 [4:10:03<1:50:47,  2.18s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-154.00max_-226.12avg_-364.00min__1623692292.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|#######9  | 11999/15000 [4:12:43<44:57,  1.11episodes/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-225.88avg_-339.00min__1623692454.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|########  | 12049/15000 [4:15:23<4:27:35,  5.44s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-145.00max_-225.80avg_-323.00min__1623692612.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|########  | 12099/15000 [4:17:20<1:31:52,  1.90s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-150.00max_-219.70avg_-324.00min__1623692740.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|########  | 12149/15000 [4:19:32<2:29:04,  3.14s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-149.00max_-216.92avg_-298.00min__1623692860.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|########1 | 12199/15000 [4:21:23<1:26:39,  1.86s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-213.92avg_-261.00min__1623692995.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 82%|########1 | 12249/15000 [4:23:56<1:24:06,  1.83s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-218.50avg_-407.00min__1623693124.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 82%|########1 | 12299/15000 [4:26:03<2:09:18,  2.87s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___151.00max_-211.62avg_-312.00min__1623693252.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 82%|########2 | 12349/15000 [4:28:37<3:31:26,  4.79s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-157.00max_-226.42avg_-315.00min__1623693408.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 83%|########2 | 12399/15000 [4:30:55<1:15:58,  1.75s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-152.00max_-222.70avg_-342.00min__1623693546.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 83%|########2 | 12449/15000 [4:33:07<2:10:36,  3.07s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-157.00max_-218.46avg_-384.00min__1623693675.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 83%|########3 | 12499/15000 [4:35:25<58:05,  1.39s/episodes]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-181.00max_-224.98avg_-320.00min__1623693816.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|########3 | 12549/15000 [4:37:19<1:32:58,  2.28s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-153.00max_-213.50avg_-367.00min__1623693928.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|########3 | 12599/15000 [4:39:50<4:08:16,  6.20s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___199.00max_-214.76avg_-323.00min__1623694079.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|########4 | 12649/15000 [4:42:06<1:53:57,  2.91s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___209.00max_-215.34avg_-328.00min__1623694229.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|########4 | 12699/15000 [4:44:21<1:01:42,  1.61s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-215.42avg_-323.00min__1623694354.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|########4 | 12749/15000 [4:46:23<1:18:04,  2.08s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-217.38avg_-276.00min__1623694476.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|########5 | 12799/15000 [4:48:45<1:25:09,  2.32s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-141.00max_-221.74avg_-439.00min__1623694613.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|########5 | 12849/15000 [4:51:39<1:09:41,  1.94s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-175.00max_-228.14avg_-374.00min__1623694793.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|########5 | 12899/15000 [4:53:57<2:59:42,  5.13s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-165.00max_-221.06avg_-308.00min__1623694927.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|########6 | 12949/15000 [4:56:29<2:31:54,  4.44s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___192.00max_-215.96avg_-385.00min__1623695081.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|########6 | 12998/15000 [4:58:48<49:06,  1.47s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-150.00max_-218.66avg_-373.00min__1623695218.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|########6 | 13049/15000 [5:00:39<2:01:43,  3.74s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-211.62avg_-246.00min__1623695329.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|########7 | 13099/15000 [5:02:48<2:29:13,  4.71s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-218.46avg_-299.00min__1623695457.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 88%|########7 | 13149/15000 [5:05:44<3:09:34,  6.14s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-226.92avg_-380.00min__1623695638.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 88%|########7 | 13199/15000 [5:08:31<1:46:16,  3.54s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-224.04avg_-331.00min__1623695801.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 88%|########8 | 13249/15000 [5:10:41<1:04:59,  2.23s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-153.00max_-225.18avg_-448.00min__1623695935.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 89%|########8 | 13299/15000 [5:14:03<1:33:49,  3.31s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-176.00max_-236.16avg_-352.00min__1623696133.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 89%|########8 | 13349/15000 [5:15:47<39:10,  1.42s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-182.00max_-217.22avg_-317.00min__1623696238.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 89%|########9 | 13399/15000 [5:18:30<3:44:31,  8.41s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-173.00max_-222.70avg_-325.00min__1623696399.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|########9 | 13449/15000 [5:20:56<42:13,  1.63s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-170.00max_-226.18avg_-370.00min__1623696544.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|########9 | 13499/15000 [5:23:15<1:13:01,  2.92s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-145.00max_-222.44avg_-334.00min__1623696686.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|######### | 13549/15000 [5:25:45<1:56:40,  4.82s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-156.00max_-219.32avg_-309.00min__1623696835.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|######### | 13599/15000 [5:28:54<1:45:25,  4.51s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___208.00max_-223.58avg_-335.00min__1623697034.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|######### | 13649/15000 [5:31:55<1:12:16,  3.21s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-164.00max_-229.44avg_-328.00min__1623697207.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|#########1| 13699/15000 [5:34:56<49:10,  2.27s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-221.42avg_-394.00min__1623697387.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92%|#########1| 13749/15000 [5:38:15<1:31:56,  4.41s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-235.78avg_-400.00min__1623697584.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92%|#########1| 13799/15000 [5:41:55<1:09:35,  3.48s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-170.00max_-233.74avg_-330.00min__1623697806.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92%|#########2| 13849/15000 [5:44:39<1:57:06,  6.11s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-223.90avg_-313.00min__1623697969.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 93%|#########2| 13899/15000 [5:47:18<40:26,  2.20s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___146.00max_-214.88avg_-317.00min__1623698130.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 93%|#########2| 13949/15000 [5:50:36<1:48:18,  6.18s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-149.00max_-227.42avg_-367.00min__1623698327.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 93%|#########3| 13999/15000 [5:54:22<54:10,  3.25s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___196.00max_-223.26avg_-409.00min__1623698551.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 94%|#########3| 14049/15000 [5:56:50<36:59,  2.33s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___207.00max_-222.84avg_-445.00min__1623698699.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 94%|#########3| 14099/15000 [5:59:42<33:42,  2.25s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-149.00max_-224.72avg_-359.00min__1623698871.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 94%|#########4| 14149/15000 [6:03:12<51:48,  3.65s/episodes]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___208.00max_-222.60avg_-353.00min__1623699081.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|#########4| 14199/15000 [6:06:31<36:03,  2.70s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-140.00max_-227.02avg_-357.00min__1623699280.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|#########4| 14249/15000 [6:09:35<30:33,  2.44s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-228.66avg_-374.00min__1623699466.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|#########5| 14299/15000 [6:12:37<35:56,  3.08s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-150.00max_-229.30avg_-464.00min__1623699647.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 96%|#########5| 14349/15000 [6:16:19<38:45,  3.57s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-139.00max_-233.52avg_-379.00min__1623699872.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 96%|#########5| 14399/15000 [6:19:22<30:11,  3.01s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___204.00max_-226.74avg_-495.00min__1623700054.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 96%|#########6| 14449/15000 [6:22:39<52:48,  5.75s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256___207.00max_-218.90avg_-322.00min__1623700249.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97%|#########6| 14499/15000 [6:25:27<22:43,  2.72s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-143.00max_-225.80avg_-433.00min__1623700417.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97%|#########6| 14549/15000 [6:28:50<40:22,  5.37s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-149.00max_-235.16avg_-371.00min__1623700620.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97%|#########7| 14599/15000 [6:32:17<20:34,  3.08s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-142.00max_-225.36avg_-336.00min__1623700828.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 98%|#########7| 14649/15000 [6:35:45<21:44,  3.72s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-201.00max_-234.02avg_-350.00min__1623701035.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 98%|#########7| 14699/15000 [6:39:04<29:09,  5.81s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-201.00max_-240.94avg_-525.00min__1623701246.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 98%|#########8| 14749/15000 [6:42:33<08:12,  1.96s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-147.00max_-234.98avg_-438.00min__1623701448.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|#########8| 14799/15000 [6:45:33<08:55,  2.67s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-200.00max_-228.70avg_-335.00min__1623701624.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|#########8| 14849/15000 [6:48:32<06:47,  2.70s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-164.00max_-224.32avg_-337.00min__1623701801.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|#########9| 14899/15000 [6:51:51<07:05,  4.21s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-150.00max_-233.12avg_-385.00min__1623702004.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|#########9| 14949/15000 [6:55:03<06:40,  7.85s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-146.00max_-228.46avg_-333.00min__1623702192.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|#########9| 14999/15000 [6:58:08<00:01,  1.90s/episodes]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/2x256__-144.00max_-229.58avg_-358.00min__1623702377.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 15000/15000 [6:58:10<00:00,  1.67s/episodes]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4VodgzxtTi3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}